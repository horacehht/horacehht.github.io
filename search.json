[{"title":"test","url":"/2021/05/27/test/","content":"æµ‹è¯•ç»ˆäºæå¥½äº†555\nå¥½å¼€å¿ƒâ€¦..\n","tags":["æµ‹è¯•","è¯•ä¸€ä¸‹èƒ½ä¸èƒ½å¤šä¸ªæ ‡ç­¾"]},{"title":"åˆ©ç”¨hexoæ¡†æ¶æ­å»ºä¸ªäººåšå®¢","url":"/2021/05/29/%E5%88%A9%E7%94%A8hexo%E6%A1%86%E6%9E%B6%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/","content":"åˆ©ç”¨hexoæ¡†æ¶æ­å»ºä¸ªäººåšå®¢å®‰è£…gitç”±äºæˆ‘ä¹‹å‰å®‰è£…äº†å°±ä¸è¯´äº†\nå¯ä»¥ç™¾åº¦æœç´¢ğŸ”gitå®˜ç½‘ã€‚gitæ˜¯å¯ä»¥ä¸€ç›´æ— è„‘ä¸‹ä¸€æ­¥å®‰è£…çš„ã€‚ç›¸ä¿¡è¿™ä¸ä¼šéš¾å€’èªæ˜çš„ä½ \nå®‰è£…nodejsè¿›å…¥å®˜ç½‘é€‰æ‹©å¯¹åº”çš„ç‰ˆæœ¬è¿›è¡Œä¸‹è½½\nå®‰è£…æ—¶ä¸€è·¯nextå³å¯ï¼ˆè·¯    å¾„ä½ è‡ªå·±é€‰ï¼‰\nå®‰è£…æˆåŠŸåï¼Œwin+Rï¼Œè¾“å…¥cmdè¿›å…¥å‘½ä»¤è¡Œï¼Œè¾“å…¥\nnode -vnpm -v\n\næ£€æŸ¥æ˜¯å¦å®‰è£…æˆåŠŸ\nå¦‚æœå‘ˆç°è¿™æ ·çš„å°±ç•Œé¢ï¼Œåˆ™è¡¨ç¤ºå®‰è£…æˆåŠŸ\n\nå¦å¤–ï¼Œå¯ä»¥ç”¨git bashä»£æ›¿å‘½ä»¤è¡Œæ¥æ•²å‘½ä»¤\nå®‰è£…hexoè‡ªå·±åˆ›å»ºä¸€ä¸ªæ–‡ä»¶å¤¹ï¼Œæˆ‘è¿™é‡Œæ–°å»ºäº†ä¸€ä¸ªblogæ–‡ä»¶å¤¹ï¼Œç‚¹è¿›å»åå³é”®git bash here\ngit bashå†…è¾“å…¥hexo init nameï¼Œè¿™é‡Œçš„nameä½ çˆ±æ€ä¹ˆå¡«æ€ä¹ˆå¡«\nè¿‡ç¨‹ä¸­å¯èƒ½ä¼šæŠ¥é”™OpenSSL SSL_read: Connection was reset, errno 10054\næœ€æœ‰å¯èƒ½æ˜¯ç½‘ç»œä¸ç¨³å®šï¼Œgithubç»å¸¸è¿™æ ·ï¼Œè‡³äºåŸå› ï¼Œå¤§å®¶æ‡‚å¾—éƒ½æ‡‚ï¼Œæœ‰æ—¶å€™ç§‘å­¦ä¸Šç½‘ä¹‹åä¹Ÿæ˜¯è¿™æ ·ã€‚\nè¿™é‡Œæˆ‘è¾“å…¥äº†hexo init Horace\n\n\nå‡ºç°è¿™æ ·çš„ç•Œé¢å³åˆå§‹åŒ–æˆåŠŸ\néšåï¼Œcd Horaceè¿›å…¥åˆšåˆšåˆå§‹åŒ–çš„æ–‡ä»¶å¤¹å†…ï¼Œè¾“å…¥npm install\n\néšåè¾“å…¥\nhexo ghexo server\n\næˆ–æ˜¯è¾“å…¥hexo s\næ‰“å¼€hexoæœåŠ¡ï¼Œæµè§ˆå™¨è¾“å…¥localhost:4000ï¼Œå³å¯çœ‹åˆ°åˆšåˆšåˆ›å»ºçš„åšå®¢äº†ã€‚é•¿è¿™æ ·å­ï¼š\n\nå¯ä»¥é€šè¿‡Ctrl+Cåœæ­¢hexoæœåŠ¡ã€‚\nåœæ­¢æœåŠ¡åï¼Œå†è¾“å…¥localhost:4000å°±ç™»ä¸ä¸Šç½‘ç«™äº†ã€‚\néƒ¨ç½²åˆ°äº‘ç«¯è¿™é‡Œå¯ä»¥çœ‹åˆ°ï¼Œæˆ‘ä»¬è¾“å…¥çš„ç½‘å€æ˜¯localhost:4000ï¼Œå¹¶ä¸æ˜¯ä¸ªé™æ€é“¾æ¥\nè€Œæˆ‘ä»¬æ­ä¸ªäººåšå®¢æœ¬èº«å°±æ˜¯æƒ³åˆ«äººæ¥çœ‹çš„ï¼Œå¦‚æœåˆ«äººéƒ½ç‚¹ä¸è¿›æ¥ï¼Œé‚£æœ‰ä»€ä¹ˆæ„ä¹‰å•Šï¼Ÿ\næ‰€ä»¥ï¼Œè¦è®©æˆ‘ä»¬çš„ä¸ªäººåšå®¢å¯ä»¥è¢«åˆ«äººè®¿é—®åˆ°ï¼Œæˆ‘ä»¬å¯ä»¥å°†æˆ‘ä»¬çš„ç½‘ç«™éƒ¨ç½²åˆ°äº‘ç«¯ï¼ˆä¸æ˜¯å”¯ä¸€çš„æ–¹å¼ï¼‰\nè¿™é‡Œå°±è®©githubæ‰˜ç®¡æˆ‘ä»¬çš„åšå®¢ã€‚\nåˆ›å»ºgithubè´¦æˆ·ä¸åˆ›å»ºå¯¹åº”ä»“åº“æ³¨å†Œä¸€ä¸ªgithubè´¦æˆ·ï¼Œåˆ›å»ºï¼ˆnewï¼‰ä¸€ä¸ªä»“åº“ï¼Œä»“åº“åå«ç”¨æˆ·å+.github.io\næˆ‘çš„ç”¨æˆ·åæ˜¯horacehhtï¼Œå› æ­¤åˆ›å»ºä¸€ä¸ªhoracehht.github.ioçš„ä»“åº“\nç”ŸæˆSSHæ·»åŠ åˆ°githubå‚è€ƒå»–é›ªå³°åšå®¢gitæ–‡ç« \nå°†hexoéƒ¨ç½²åˆ°äº‘ç«¯é€šè¿‡npm install hexo-deployer-git --saveå‘½ä»¤ä¸‹è½½éƒ¨ç½²çš„ç›¸åº”æ’ä»¶\nç„¶å\nhexo cleanhexo generatehexo deploy\n\nä½†æ˜¯ä¹‹åè®¿é—®http://horacehht.github.ioæŠ¥é”™404ï¼Œè¯´There isn&#39;t a GitHub Pages site here.\næœ€åé€šè¿‡github pageçš„å®˜æ–¹æ–‡æ¡£å¾—çŸ¥ï¼Œå¦‚æœè¦ä½œä¸ºä¸€ä¸ªGithub Pagesä»“åº“ï¼Œéœ€æ»¡è¶³ä¸‰ä¸ªæ¡ä»¶ï¼š\n\nä»“åº“åä¸ºç”¨æˆ·å+github.io\nä»“åº“åº”è®¾ä¸ºpublicï¼ˆå…¬å¼€ï¼‰\nä»“åº“å†…è¦åˆ›å»ºä¸€ä¸ªREADMEæ–‡æ¡£\n\nhexoçš„åŸºæœ¬å‘½ä»¤\n\n\nå‘½ä»¤\nä½œç”¨\n\n\n\nHexo init\nåˆå§‹åŒ–åšå®¢\n\n\nHexo s\nè¿è¡Œåšå®¢\n\n\nHexo n title\nåˆ›å»ºä¸€ç¯‡æ–°çš„æ–‡ç« ï¼Œtitleä¸ºæ–‡ç« æ ‡é¢˜\n\n\nHexo c(clean)\næ¸…ç†æ–‡ä»¶\n\n\nHexo g(GENERATE)\nç”Ÿæˆé™æ€æ–‡ä»¶\n\n\nHexo d(deploy)\néƒ¨ç½²åšå®¢\n\n\n\n\nhexoé¡¹ç›®çš„_config.ymlæ˜¯æ•´ä¸ªhexoé¡¹ç›®çš„æ€»é…ç½®æ–‡ä»¶ï¼Œå¦‚æœéœ€è¦é…ç½®ä¸»é¢˜ï¼Œåˆ™è¿˜æœ‰å¯¹åº”ä¸»é¢˜çš„é…ç½®æ–‡ä»¶ã€‚\nä¸»é¢˜æŒ‘é€‰æŒ‘é€‰ä¸»é¢˜ä¸­â€¦selecting\n1.Yunä¸»é¢˜æ˜¯æˆ‘æœ€å–œæ¬¢çš„ä¸€ä¸ªä¸»é¢˜ï¼Œä½†æ˜¯å› ä¸ºä¸€äº›ç‰¹æ®ŠåŸå› ï¼Œæ€•å®¡ç¾ç–²åŠ³ï¼Œå°±ä¸ç”¨äº†ã€‚demoï¼šhttps://www.yunyoujun.cn/\ngithubåœ°å€ï¼šhttps://github.com/YunYouJun/hexo-theme-yun\n2.Anatoleä¸»é¢˜ä¹Ÿå¯ï¼Œå¾ˆç®€æ´ï¼Œä½†ä¸å–œæ¬¢ã€‚demoï¼šhttps://www.jixian.io/\ngithubåœ°å€ï¼šhttps://github.com/mrcore/hexo-theme-Anatole-Core\n3.Ayerä¸»é¢˜ã€‚å¾ˆå…¨é¢çš„ä¸€ä¸ªä¸»é¢˜ã€‚demoï¼šhttps://shen-yu.gitee.io/\ngithubåœ°å€ï¼šhttps://github.com/Shen-Yu/hexo-theme-ayer\næ„Ÿè§‰éå¸¸ä¸é”™ã€‚\n4.Particleä¸»é¢˜ã€‚ç®€æ´ã€‚ä½†æ–‡ç« æ²¡æœ‰ç›®å½•ã€‚demoï¼šhttps://korilin.com/\ngithubåœ°å€ï¼šhttps://github.com/korilin/hexo-theme-particle\n5.shokaä¸»é¢˜ã€‚äº¤äº’æ€§å¼ºï¼Œå­—ä½“å¥½çœ‹ï¼Œå¼•ç”¨å—å¥½çœ‹ã€‚demoï¼šhttps://shoka.lostyu.me/\ngithubåœ°å€ï¼šhttps://github.com/amehime/hexo-theme-shoka\næœ‰ç‚¹èŠ±\n6.Keepä¸»é¢˜ã€‚åˆ‡æ¢è‡ªç„¶ã€‚ä¸»é¡µé¢ç®€æ´ã€‚demoï¼šhttps://xpoet.cn/\ngithubåœ°å€ï¼šhttps://github.com/XPoet/hexo-theme-keep\næœ€ç»ˆé€‰å®šKeepè¿™ä¸ªä¸»é¢˜ï¼ç®€æ´åˆå¥½çœ‹ \nä½¿ç”¨Keepä¸»é¢˜æ³¨ï¼šé…ç½®æ–‡ä»¶æœ‰ä¸¤ä¸ªï¼šæ€»é…ç½®æ–‡ä»¶ï¼Œä¸»é¢˜é…ç½®æ–‡ä»¶ã€‚ä¸‹æ–‡æåˆ°æ—¶æ³¨æ„åŒºåˆ†\nå®‰è£…ä¸»é¢˜åœ¨git bashä¸­æ‰§è¡Œå‘½ä»¤\ngit clone https://github.com/XPoet/hexo-theme-keep themes/keep\n\nç„¶åthemesæ–‡ä»¶å¤¹ä¸‹å‡ºç°æˆ‘ä»¬æƒ³è¦çš„keepä¸»é¢˜ã€‚\n\nè¿™ä¸ªä¸ºä¸»é¢˜é…ç½®æ–‡ä»¶ï¼ˆè¿™é‡Œè¸©äº†ä¸€äº›å‘ï¼Œé€šè¿‡npmå®‰è£…çš„æ²¡æœ‰è¿™ä¸ªæ–‡ä»¶å¤¹ï¼‰\nä½¿ç”¨ä¸»é¢˜å®‰è£…å®Œæˆåï¼Œåœ¨ Hexoé¡¹ç›®çš„æ€»é…ç½®æ–‡ä»¶ä¸­å°† theme è®¾ç½®ä¸º keepã€‚\ntheme: keep\n\nè¿™ä¸ªæ–‡ä»¶çš„è·¯å¾„ä¸ºname\\_config.ymlï¼Œæˆ‘çš„ä¸ºHorace\\_config.yml\n\nkeepä¼šä¸å®šæœŸæ›´æ–°ç‰ˆæœ¬ï¼Œå¯é€šè¿‡å¦‚ä¸‹å‘½ä»¤æ›´æ–°Keepã€‚\n\né€šè¿‡ npm å®‰è£…æœ€æ–°ç‰ˆæœ¬ï¼š\n$ cd hexo-siteï¼ˆhexoé¡¹ç›®çš„ä½ç½®ï¼‰$ npm update hexo-theme-keep\n\næˆ–\n\né€šè¿‡ git æ›´æ–°åˆ°æœ€æ–°çš„ master åˆ†æ”¯ï¼š\n$ cd themes/keep$ git pull\n\né…ç½®æŒ‡å—å¤åˆ¶ä¸»é¢˜é…ç½®æ–‡ä»¶ã€‚å›åˆ°æ•´ä¸ªåšå®¢é¡¹ç›®ç›®å½•ä¸‹çš„sourceæ–‡ä»¶å¤¹ï¼Œæ–°å»ºä¸€ä¸ªæ–‡ä»¶å¤¹_dataï¼Œå°†è¯¥æ–‡ä»¶ç²˜è´´è¿›å»\n\nå°†æ–‡ä»¶åæ›´æ”¹ä¸ºkeep.ymlï¼Œè¿™å¾ˆé‡è¦ï¼\nç„¶åé€šè¿‡è¯¥æ–‡ä»¶æ¥è¿›è¡Œç›¸åº”çš„ä¿®æ”¹å³å¯å®ç°å¯¹ä¸»é¢˜çš„é…ç½®ï¼\nè¿™äº›æ˜¯keepå®˜æ–¹æä¾›çš„é…ç½®èµ„æ–™ï¼Œå·²ç»å¾ˆå…¨é¢äº†ã€‚\nhttps://keep-docs.xpoet.cn/usage-tutorial/quick-start.html#%E5%AE%89%E8%A3%85\nhttps://keep-docs.xpoet.cn/usage-tutorial/configuration-guide.html#base-info\nhttps://keep-docs.xpoet.cn/usage-tutorial/advanced.html\nè¿™ä¸‰ä¸ªéƒ½æ˜¯å®˜æ–¹ç»™çš„keepä½¿ç”¨æ•™ç¨‹ï¼Œåˆ†åˆ«ä¸ºå¿«é€Ÿå¼€å§‹ï¼Œé…ç½®æŒ‡å—å’Œè¿›é˜¶ä½¿ç”¨ï¼Œèƒ½æ»¡è¶³å¤§éƒ¨åˆ†äººçš„éœ€æ±‚\n\nä¸‹é¢ä»…ä»¥base_infoä¸ºä¾‹è®²è§£ï¼Œå…¶ä»–çš„é…ç½®é¡¹è¯·å‚è€ƒå®˜æ–¹èµ„æ–™\nbase_infoé¡¹\næ ¹æ®è‡ªå·±çš„å†…å®¹è¿›è¡Œå¡«å†™\nbase_info:  title: Horaceã®äº‘ç«¯æ¢¦å¢ƒ  author: Horace  url: https://horacehht.github.io/  # è¿™é‡Œå¡«ä¸Šhttps://ç”¨æˆ·å.github.io\tå¦‚æœè‡ªå·±æ³¨å†Œäº†åŸŸåï¼Œå°±æ”¹æˆæ³¨å†Œçš„  # å›¾æ ‡çš„é“¾æ¥ï¼Œå¯ä»¥ç”¨æœ¬åœ°çš„å›¾ç‰‡ï¼Œä¹Ÿå¯ç”¨å›¾ç‰‡é“¾æ¥ï¼Œæˆ–è€…ä¸å¡«  logo_img: https://horacehhtbucket.oss-cn-guangzhou.aliyuncs.com/img/ç½‘ç«™å›¾æ ‡.jpg  # è¿™é‡Œæˆ‘å¡«äº†ä¸€ä¸ªç½‘é¡µé“¾æ¥\n\nè¯»è€…å¯ä»¥ç¨å¾®äº†è§£å›¾åºŠï¼Œè¿™é‡Œæˆ‘è´­ä¹°äº†é˜¿é‡Œäº‘çš„å¯¹è±¡å­˜å‚¨æœåŠ¡ossä½œä¸ºå›¾åºŠæ”¾ç½®æˆ‘çš„å›¾ç‰‡\nè¯»è€…åŒæ ·ä¹Ÿå¯ä½¿ç”¨å…è´¹çš„å›¾åºŠï¼š\n\nsm.ms\n\nè·¯è¿‡å›¾åºŠ\n\n\nåˆ©ç”¨é˜¿é‡Œäº‘ä½œå›¾åºŠçš„æ–‡ç« ï¼šhttps://zhuanlan.zhihu.com/p/138878534\nå°tipsæ–‡ç« éƒ½æ”¾åœ¨sourceçš„_postsæ–‡ä»¶å¤¹ä¸‹\næ–‡ç« å¦‚æœæƒ³æ”¾åœ¨å¤šä¸ªåˆ†ç±»æˆ–å¤šä¸ªæ ‡ç­¾ä¸‹ï¼ˆå‰ææ˜¯ä½ å¼€äº†åˆ†ç±»å’Œæ ‡ç­¾çš„åŠŸèƒ½ï¼‰ï¼Œéœ€è¦å†™æˆ[a,b,c]çš„æ ¼å¼ï¼Œå¦‚å›¾ï¼š\n\næ€»ç»“ä¹‹åæ¯æ¬¡å†™æ–°æ–‡ç« ï¼Œå°±è¿›git bashä¸­æ•²\nhexo cleanhexo generatehexo deploy\n\nè¿™æ ·å°±èƒ½åœ¨è‡ªå·±çš„åšå®¢ç½‘ç«™ä¸Šçœ‹åˆ°æ–°å‘å¸ƒçš„æ–‡ç« äº†ï¼\nå¦‚æœå«Œéº»çƒ¦çš„å¯ä»¥å‚è€ƒè¿™ç¯‡æ–‡ç« è¿›è¡Œè‡ªåŠ¨éƒ¨ç½²\næˆ‘çš„åšå®¢ç½‘ç«™ä¸ºï¼šhttps://horacehht.github.io\næ¬¢è¿æ¥è®¿\n","categories":["hexo"]},{"title":"è®¾ç½®ä»£ç†çˆ¬å–è±†ç“£ä¹¦ç±","url":"/2021/05/29/%E8%AE%BE%E7%BD%AE%E4%BB%A3%E7%90%86%E7%88%AC%E5%8F%96%E8%B1%86%E7%93%A3%E4%B9%A6%E7%B1%8D/","content":"è®¾ç½®ä»£ç†çˆ¬å–è±†ç“£ä¹¦ç±ç®€ä»‹çˆ¬å–ç½‘é¡µå¤§éƒ½å¯åˆ†ä¸ºä¸‰ä¸ªæ­¥éª¤ï¼š\n\nè®¿é—®ç½‘é¡µï¼šä¸€èˆ¬ä½¿ç”¨requestsåº“ï¼Œä¸å«Œéº»çƒ¦çš„è¯å¯ä»¥ä½¿ç”¨pythonå†…ç½®çš„urllibåº“\nè§£æç½‘é¡µï¼šä½¿ç”¨Xpathï¼ŒBeautifulSoupï¼Œæ­£åˆ™è¡¨è¾¾å¼ç­‰æ–¹å¼è¿›è¡Œç½‘é¡µä¿¡æ¯çš„æå–\nå­˜å‚¨æ•°æ®ï¼šâ‘ å­˜å…¥IOæµæ–‡ä»¶ï¼Œå¦‚txtï¼Œcsvç­‰æ–‡ä»¶    â‘¡å­˜å…¥æ•°æ®åº“ï¼Œä¸»æµçš„æœ‰MySQLï¼Œmongodb\n\næœ¬æ–‡å¼€å‘ç¯å¢ƒä¸ºpython3.8ï¼Œçˆ¬å–çš„æ•°æ®å­˜å…¥MySQLæ•°æ®åº“ä¸­\nè®¿é—®ç½‘é¡µimport requestsurl = &#x27;ç›®æ ‡ç½‘å€&#x27;res = requests.get(url)\n\nè¿™æ ·å³å¯å®Œæˆä¸€æ¬¡ç½‘é¡µçš„è®¿é—®ã€‚ä½†ä¸€èˆ¬éƒ½è¦åŠ ä¸Šè¯·æ±‚å¤´ï¼Œç§°ä¸ºheadersã€‚ä¸€èˆ¬çš„ç½‘ç«™è¯·æ±‚çš„headersä¸­åŠ å…¥User-Agenté¡¹å‚æ•°å³å¯ã€‚\nå¦‚æœä½ ç”¨çš„æ˜¯è°·æ­Œæµè§ˆå™¨ï¼Œå¯åœ¨ç½‘é¡µæ è¾“å…¥chrome::versionæŸ¥çœ‹è‡ªå·±çš„User-Agenté¡¹ï¼Œå«â€œç”¨æˆ·ä»£ç†â€\n\nå¦‚æœä¸æ˜¯ï¼Œä¹Ÿå¯ä»¥æŒ‰F12ï¼ŒCtrl+Rï¼Œéšä¾¿ç‚¹è¿›ä¸€ä¸ªè¯·æ±‚ï¼ŒRequests Headersé¡¹ä¸­çš„User-Agentå°±æ˜¯ä½ çš„User-Agentã€‚\näºæ˜¯ä»£ç åº”è¯¥æ”¹æˆè¿™æ ·\nheaders = &#123;    &#x27;User-Agent&#x27;: &#x27;å¡«å…¥ä½ çš„user-agent&#x27;    ...æ ¹æ®ä¸åŒçš„ç½‘ç«™åŠ å…¥ä¸åŒçš„å‚æ•°&#125;res = requests.get(url, headers=headers)\n\nä¸åŠ çš„è¯ï¼Œä½ çš„è¯·æ±‚ä¸­User-Agentçš„å€¼åˆ™æ˜¯pythonçˆ¬è™«ï¼Œç½‘ç«™å°±ä¼šæ‹’ç»è®¿é—®ï¼Œè¿™æ ·ä½ å°±æ— æ³•å¾—åˆ°ç½‘ç«™è¿”å›çš„æ•°æ®ã€‚\nè®¾ç½®ä»£ç†ä¸ºä»€ä¹ˆè¦è®¾ç½®ä»£ç†ï¼ŸèƒŒæ™¯ï¼šæœ¬äººè¦åœ¨æŸæ¬¡è€ƒæ ¸ä»»åŠ¡æœ€åä¸€å¤©ä¸­çˆ¬å–æ•°æ®é‡è¶…è¿‡3k5çš„æ•°æ®ï¼Œæ—¶é—´ç´§ï¼Œæ•°æ®é‡è¯´å°ä¸å°ï¼Œè¯´å¤§ä¸å¤§ã€‚å¦‚æœé‡‡ç”¨å¹³å¸¸çš„çˆ¬è™«æ–¹æ³•ï¼Œæ¯ä¸€æ¬¡time.sleepå‡ ç§’ï¼Œè¿™æ ·ä¹…äº†ï¼Œè±†ç“£è‡ªç„¶ä¼šå‘ç°ï¼Œç„¶åæŠŠipç»™å°äº†ï¼Œè¿™æ ·å°±æ²¡åŠæ³•çˆ¬äº†ï¼Œè€ƒæ ¸ä»»åŠ¡å°±æ³¡æ±¤äº†â€¦\né¢˜å¤–è¯ï¼štime.sleep()è®¾ç½®çš„ç§’æ•°æœ€å¥½æ˜¯éšæœºæ•°ï¼Œå¦‚æœæ˜¯å›ºå®šçš„ç§’æ•°ï¼Œä¹…è€Œä¹…ä¹‹ä¹Ÿå¾ˆå®¹æ˜“è¢«å°ipã€‚\næ‰€ä»¥ï¼Œè®¾ç½®ä»£ç†è¿™ç§åˆ‡æ¢ipçš„æ–¹å¼å°±å¾ˆé€‚åˆçŸ­æ—¶é—´çˆ¬å–å¤§é‡æ•°æ®\nä»£ç†æœ‰å¤šç§\nâ‘ è‡ªå·±å»çˆ¬å–å…è´¹çš„ä»£ç†ï¼Œå»ºç«‹è‡ªå·±çš„ä»£ç†æ± ï¼Œéš¾åº¦å¤§ï¼ŒæŠ€æœ¯è¦æ±‚é«˜ï¼Œä¸”å¤§å¤šå…è´¹ä»£ç†éƒ½æ˜¯ç”¨ä¸äº†çš„ã€‚\nâ‘¡ä½¿ç”¨ä»˜è´¹ä»£ç†\næœ¬æ–‡ä¸­ä½¿ç”¨çš„æ˜¯ä»˜è´¹ä»£ç†ï¼Œå«å¤šè´äº‘ä»£ç†ï¼Œè´­ä¹°äº†httpéš§é“ä»£ç†ä¸­çš„å¥—é¤3ï¼Œå¥—é¤çš„ç‰¹ç‚¹æ˜¯ï¼šæ¯ä¸ªè¯·æ±‚éšæœºåˆ†é…IP\næ³¨ï¼šè´­ä¹°æ—¶éœ€è¦å®åè®¤è¯\nè·å–åˆ†é…çš„ipæ³¨ï¼šä¸åŒçš„ä»˜è´¹ä»£ç†ä¸åŒçš„å¥—é¤è·å–ipçš„æ–¹å¼ä¸åŒï¼Œæ ¹æ®å®˜æ–¹æŒ‡ç¤ºå³å¯\nè´­ä¹°åï¼Œå¤šè´äº‘ä¼šåˆ†é…ä¸€ä¸ªè´¦å·ï¼Œå¯†ç å’ŒæœåŠ¡å™¨åœ°å€ç»™ä½ \n\næ ¹æ®ä»–çš„æŒ‡å¼•æ„é€ ä»£ç†å‚æ•°å³å¯\n\näºæ˜¯æˆ‘ä»¬å‘æœåŠ¡å™¨åœ°å€ç«¯å£è¯·æ±‚ï¼ŒæœåŠ¡å™¨å³å¯è¿”å›ä¸€ä¸ªå¯ç”¨çš„ipæ¥ä¼ªè£…æˆ‘ä»¬çš„ip\nè®¿é—®ç½‘é¡µå‡½æ•°äºæ˜¯æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªè®¿é—®ç½‘é¡µçš„å‡½æ•°ï¼Œè¿”å›å“åº”ã€‚\ndef visit(targetUrl):    &quot;&quot;&quot;è®¿é—®ç½‘å€ï¼Œè¿”å›å“åº”&quot;&quot;&quot;    session = requests.Session()    session.keep_alive = False    res = session.get(targetUrl, proxies=proxies, headers=random.choice(headers))    return res\n\nè¿™é‡Œæˆ‘è¿˜ç”¨äº†éšæœºUAï¼Œå°±æ˜¯æ‰¾äº†ä¸åŒçš„user-agentï¼Œæ¯æ¬¡è®¿é—®ä»ä¸­éšæœºé€‰å–ä¸€ä¸ªuaã€‚\nè¿™é‡Œçš„headersæ˜¯ä¸ªåˆ—è¡¨\n\nè§£æç½‘é¡µæŒ‰F12æˆ–å³é”®æ£€æŸ¥è¿›å…¥â€œå¼€å‘è€…é€‰é¡¹â€ï¼Œåˆ©ç”¨å›¾ç‰‡ä¸­çº¢æ¡†çš„åŠŸèƒ½å¯ä»¥è¿…é€Ÿå®šä½æ‰€æå–ä¿¡æ¯çš„èŠ‚ç‚¹ä½ç½®\n\næ­¤å¤„è¿ç”¨XPthå’ŒBeautifulSoupè¿›è¡Œç½‘é¡µçš„è§£æï¼Œå¹¶å°†è§£ææ–¹æ³•ç¼–å†™æˆç±»ã€‚\næ³¨ï¼šå»ºè®®å¯¹è‡ªå·±çš„è§£ææ–¹æ³•å¤šå¯¹å‡ æœ¬ä¹¦è¿›è¡Œå°è¯•ï¼Œå› ä¸ºä¸åŒç½‘é¡µæ’ç‰ˆå¯èƒ½ä¸åŒå™¢~\nçˆ¬å–çš„å­—æ®µä¸ºbook_nameï¼ˆä¹¦åï¼‰ï¼Œauthorï¼ˆä½œè€…ï¼‰ï¼Œpressï¼ˆå‡ºç‰ˆç¤¾ï¼‰ï¼Œpublishing_yearï¼ˆå‡ºç‰ˆå¹´ä»½ï¼‰ï¼Œpage_numï¼ˆé¡µæ•°ï¼‰ï¼Œpriceï¼ˆå®šä»·ï¼‰ï¼ŒISBNï¼Œscoreï¼ˆè¯„åˆ†ï¼‰ï¼Œrating_numï¼ˆè¯„åˆ†äººæ•°ï¼‰ï¼Œcontent_introductionï¼ˆå†…å®¹ç®€ä»‹ï¼‰ï¼Œcover_urlï¼ˆå°é¢å›¾ç‰‡ç½‘é¡µé“¾æ¥ï¼‰ï¼Œreadersï¼ˆè¯»è€…çš„ä¸ªäººä¸»é¡µé“¾æ¥ï¼‰\n# åº“å¯¼å…¥éƒ¨åˆ†import refrom lxml import etreefrom bs4 import BeautifulSoupclass CrawlBook:    def __init__(self, res):        try:            self.soup = BeautifulSoup(res.text, &#x27;lxml&#x27;)  # åˆå§‹åŒ–            self.html = etree.HTML(res.text)  # åˆå§‹åŒ–            self.data = dict()  # ç”Ÿæˆä¸€ä¸ªç©ºå­—å…¸            self.get_book_name()            self.get_author()            self.get_many()            self.get_score()            self.get_rating_num()            self.get_content()            self.get_image()            self.get_readers()        except Exception as e:            self.data.setdefault(&#x27;author&#x27;, &#x27;&#x27;)            self.data.setdefault(&#x27;å‡ºç‰ˆç¤¾:&#x27;, &#x27;&#x27;)            self.data.setdefault(&#x27;å‡ºç‰ˆå¹´:&#x27;, &#x27;&#x27;)            self.data.setdefault(&#x27;é¡µæ•°:&#x27;, &#x27;0&#x27;)            self.data.setdefault(&#x27;å®šä»·:&#x27;, &#x27;&#x27;)            self.data.setdefault(&#x27;ISBN:&#x27;, &#x27;&#x27;)            self.data.setdefault(&#x27;score&#x27;, 0.0)            self.data.setdefault(&#x27;rating_num&#x27;, 0)            self.data.setdefault(&#x27;content_introduction&#x27;, &#x27;&#x27;)            self.data.setdefault(&#x27;readers&#x27;, &#x27;[]&#x27;)            print(e)    def get_book_name(self):        book_name = self.soup.find(name=&#x27;span&#x27;, attrs=&#123;&#x27;property&#x27;: &#x27;v:itemreviewed&#x27;&#125;).string        # æ‰¾åˆ°èŠ‚ç‚¹åä¸ºspanï¼Œå±æ€§propertyå€¼ä¸ºitemreviewdçš„èŠ‚ç‚¹ï¼Œ.stringè·å–å…¶æ–‡æœ¬å†…å®¹        self.data.setdefault(&#x27;book_name&#x27;, book_name)  # å°†å…¶æ·»åŠ åˆ°å­—å…¸ä¸­ï¼Œä¸‹é¢çš„è§£ææ–¹æ³•å¤§åŒå°å¼‚    def get_author(self):        author = self.soup.find(name=&#x27;span&#x27;, text=re.compile(&#x27;.*?ä½œè€….*?&#x27;)).next_sibling.next_sibling\\            .string.replace(&#x27;\\n&#x27;, &#x27;&#x27;).replace(&#x27; &#x27;, &#x27;&#x27;)        self.data.setdefault(&#x27;author&#x27;, author)    def get_many(self):        want_to_spider = [&#x27;å‡ºç‰ˆç¤¾:&#x27;, &#x27;å‡ºç‰ˆå¹´:&#x27;, &#x27;é¡µæ•°:&#x27;, &#x27;å®šä»·:&#x27;, &#x27;ISBN:&#x27;]        for i in self.soup.find_all(name=&#x27;span&#x27;, attrs=&#123;&#x27;class&#x27;: &#x27;pl&#x27;&#125;):            if i.string in want_to_spider:                self.data.setdefault(i.string, i.next_sibling.replace(&#x27; &#x27;, &#x27;&#x27;))    def get_score(self):        score = float(self.soup.find(name=&#x27;strong&#x27;, attrs=&#123;&#x27;property&#x27;: &#x27;v:average&#x27;&#125;).string)        self.data.setdefault(&#x27;score&#x27;, score)    def get_rating_num(self):        rating_num = int(self.soup.find(name=&#x27;span&#x27;, attrs=&#123;&#x27;property&#x27;: &#x27;v:votes&#x27;&#125;).string)        self.data.setdefault(&#x27;rating_num&#x27;, rating_num)    def get_content(self):        l = &#x27;&#x27;        try:            for i in self.soup.find(name=&#x27;div&#x27;, attrs=&#123;&#x27;class&#x27;: &#x27;intro&#x27;&#125;).contents:                l += str(i)            self.data.setdefault(&#x27;content_introduction&#x27;, l.strip())        except Exception as e:            print(e)            self.data.setdefault(&#x27;content_introduction&#x27;, &#x27;&#x27;)    def get_image(self):        image_url = self.soup.find(name=&#x27;img&#x27;, attrs=&#123;&#x27;rel&#x27;: &#x27;v:photo&#x27;&#125;)[&#x27;src&#x27;]  # è·å–èŠ‚ç‚¹çš„srcå±æ€§å€¼        self.data.setdefault(&#x27;cover_url&#x27;, image_url)    def get_readers(self):        readers = str(self.html.xpath(&#x27;//*[@id=&quot;collector&quot;]//div/div[2]/a/@href&#x27;))          # è¿™é‡Œç”¨çš„æ˜¯xpathçš„è§£ææ–¹æ³•ï¼Œè·å–æ‰€æœ‰å±æ€§å€¼ä¸ºcollectorä¸‹çš„æ‰€æœ‰divèŠ‚ç‚¹ä¸‹çš„ç¬¬äºŒä¸ªdivèŠ‚ç‚¹çš„aèŠ‚ç‚¹çš„hrefå±æ€§å€¼        self.data.setdefault(&#x27;readers&#x27;, readers)\n\næ³¨ï¼šå­—å…¸çš„setdefaultå‡½æ•°æ˜¯æ·»åŠ é”®å€¼å¯¹çš„ä¸€ç§æ–¹å¼ï¼Œå¦‚æœå·²æœ‰è¿™ä¸ªé”®åˆ™ä¸æ·»åŠ ï¼Œæ²¡æœ‰åˆ™æ·»åŠ ã€‚\nè¿™å¯ä»¥çª¥æ¢å‡ºæˆ‘ä¸ºä»€ä¹ˆåœ¨try-exceptè¯­å¥çš„exceptä¸­åŠ ä¸Šç›¸åº”å­—æ®µçš„setdefaultã€‚å› ä¸ºè±†ç“£çš„ä¹¦ç±é—´ç½‘é¡µæ’å¸ƒæ˜¯ä¸åŒçš„ï¼Œå®ƒå°±æ˜¯æ¯”è¾ƒç‰¹æ®Šï¼Œæœ‰äº›ä¹¦æ²¡æœ‰ISBNï¼Œæœ‰äº›ä¹¦æ²¡æœ‰è¯„åˆ†å’Œè¯„è®ºäººæ•°â€¦æ‰€ä»¥ä»¥å›ºå®šçš„æ–¹å¼å»æå–è¿™äº›å­—æ®µï¼Œå¿…ä¼šæŠ¥é”™ï¼Œæ‰€ä»¥é‡åˆ°è¿™ç§æŠ¥é”™æ—¶ï¼Œè¿›åˆ°exceptè¯­å¥ä¸ºæ•°æ®èµ‹ä¸Šä¸€äº›æ–¹ä¾¿å¤„ç†çš„ç©ºå€¼ã€‚è™½è¯´æˆ‘ä¹Ÿä¸çŸ¥é“ä¸ºä»€ä¹ˆä¹‹åè¿˜æ˜¯æœ‰ç©ºå€¼\nå°æ’å…¥ä¸€å¥ï¼Œå¼‚å¸¸å¤„ç†çœŸçš„å¾ˆé‡è¦ï¼ï¼ï¼\ntry:    ä¸€äº›å¯èƒ½ä¼šå‡ºé”™çš„è¯­å¥except Exception as e:    print(e)  # è¿™ä¸ªprint(e)å¯ä»¥è®©æˆ‘ä»¬çœ‹åˆ°å‡ºé”™çš„åŸå› ï¼Œ    pass  # è¿™é‡Œçš„passä½ å¯ä»¥å¡«å…¥ä½ å¼‚å¸¸å¤„ç†çš„è¯­å¥\n\nè¿™æ ·å­æ‰€æœ‰çš„å­—æ®µæ•°æ®éƒ½å­˜å…¥äº†dataä¸­ï¼Œä¹‹åæˆ‘ä»¬å®ä¾‹åŒ–ä¸€ä¸ªå¯¹è±¡ï¼Œå¯¹è±¡.dataå³å¯æŸ¥çœ‹æˆ‘ä»¬çˆ¬å–çš„æ•°æ®å•¦ã€‚\næˆ‘ä»¬ä»¥ã€Šè¿½é£ç­çš„äººã€‹ä¸ºä¾‹ï¼š\n\nå­˜å‚¨æ•°æ®ä½¿ç”¨MySQLæ•°æ®åº“è¿›è¡Œæ•°æ®çš„å­˜å‚¨\nå»ºè¡¨è¦æ ¹æ®çˆ¬å–çš„å­—æ®µå»ºç«‹ç›¸åº”çš„è¡¨ï¼ˆå¦‚æœæ˜¯æ–°ç”¨æˆ·è¿˜è¦æ–°å»ºè¿æ¥ï¼Œè¿™é‡Œå°±ä¸å¤šèµ˜è¿°äº†ï¼‰\nå¯ä»¥ç”¨pythonå»ºè¡¨ï¼Œä¹Ÿå¯ä»¥ç”¨navicatï¼ˆMySQLçš„ä¸€ä¸ªå¯è§†åŒ–å·¥å…·ï¼‰å»ºè¡¨ã€‚\nè¿™é‡Œç”¨pythonå»ºè¡¨\npythoné€šè¿‡ç¬¬ä¸‰æ–¹åº“pymysqlä¸MySQLä¸æ•°æ®åº“è¿›è¡Œäº¤äº’ï¼Œå¯¹æ•°æ®è¿›è¡Œå¢åˆ æŸ¥æ”¹ã€‚\né¦–å…ˆè¦import pymysqlï¼Œæ²¡æœ‰å®‰è£…åº“çš„å°±å»å®‰è£…ã€‚\nç›´æ¥è´´ä»£ç ï¼š\nimport pymysqlconn = pymysql.connect(  # è¿æ¥æœ¬åœ°æ•°æ®åº“    host=&quot;localhost&quot;,    user=&quot;root&quot;,  # è¦å¡«root    password=&quot;htht0928&quot;,  # å¡«ä¸Šè‡ªå·±çš„å¯†ç     database=&quot;doubanbook&quot;,  # æ•°æ®åº“å    charset=&quot;utf8&quot;)cur = conn.cursor()  # è·å¾—å…‰æ ‡create_books_table_sql = &quot;&quot;&quot;     CREATE TABLE `books`(    `book_name` VARCHAR(20) NOT NULL UNIQUE,    `author` VARCHAR(20) NOT NULL,    `press` VARCHAR(20),    `publishing_year` VARCHAR(10),    `score` FLOAT,    `rating_num` INTEGER,    `page_num` VARCHAR(10),    `price` VARCHAR(10),    `ISBN` VARCHAR(30),    `content_introduction` VARCHAR(2000),    `cover_url` VARCHAR(100),    `readers` VARCHAR (400)    )&quot;&quot;&quot;  # sqlè¯­å¥try:    cur.execute(create_books_table_sql)  # æ‰§è¡Œsqlè¯­å¥except Exception as e:    print(e)    conn.rollback()  # å‘ç”Ÿé”™è¯¯åˆ™å›æ»š\n\nè¿è¡Œåå³å¯å»ºç«‹ç›¸åº”çš„è¡¨ã€‚\næ’å…¥æ•°æ®ç¼–å†™save_to_mysqlå‡½æ•°\ndef save_to_mysql(data):    &quot;&quot;&quot;dataæ˜¯ä¹¦ç±çš„ä¿¡æ¯ï¼Œjsonæ ¼å¼ï¼Œè¦æ’å…¥åˆ°booksè¿™ä¸ªè¡¨&quot;&quot;&quot;    book_name = data.get(&#x27;book_name&#x27;)    author = data.get(&#x27;author&#x27;)    press = data.get(&#x27;å‡ºç‰ˆç¤¾:&#x27;)    publishing_year = data.get(&#x27;å‡ºç‰ˆå¹´:&#x27;)    page_num = data.get(&#x27;é¡µæ•°:&#x27;)    price = data.get(&#x27;å®šä»·:&#x27;)    ISBN = data.get(&#x27;ISBN:&#x27;)    score = data.get(&#x27;score&#x27;)    rating_num = data.get(&#x27;rating_num&#x27;)    content_introduction = data.get(&#x27;content_introduction&#x27;)    cover_url = data.get(&#x27;cover_url&#x27;)    readers = data.get(&#x27;readers&#x27;)    insert_data = (book_name, author, press, publishing_year, score, rating_num, page_num, price, ISBN,                   content_introduction, cover_url, readers)    insert_sql = &quot;&quot;&quot;        INSERT INTO books(book_name, author, press, publishing_year, score, rating_num, page_num, price,        ISBN, content_introduction, cover_url, readers)        VALUES(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)    &quot;&quot;&quot;  # å‘å­—æ®µä¸­å¢æ·»ç›¸åº”çš„æ•°æ®    try:        # æ‰§è¡Œsqlè¯­å¥        cur.execute(insert_sql, insert_data)        # æäº¤æ‰§è¡Œ        conn.commit()        print(&#x27;ã€Š&#x27; + book_name + &#x27;ã€‹&#x27; + &#x27;ä¿¡æ¯å·²å­˜å‚¨æˆåŠŸ!&#x27;)  # æ–¹ä¾¿æˆ‘ä»¬çœ‹åˆ°çˆ¬å–çš„è¿‡ç¨‹    except Exception as e:        print(e)        conn.rollback()        print(&#x27;å­˜å‚¨å¤±è´¥!&#x27;)\n\næ³¨ï¼šæå–å­—å…¸æ•°æ®æ—¶æ²¡ç”¨dict[â€˜keyâ€™]çš„æ–¹æ³•è·å–çš„åŸå› æ˜¯å¦‚æœæ²¡æœ‰è¿™ä¸ªå­—æ®µï¼Œä¼šç›´æ¥æŠ¥é”™ï¼Œæ•´ä¸ªç¨‹åºç›´æ¥åœä¸‹æ¥ã€‚\nå¦‚æœç”¨.getï¼Œå³æ˜¯æ²¡æœ‰è¿™ä¸ªå­—æ®µï¼Œgetè¿™ä¸ªå­—æ®µä¼šè¿”å›Noneï¼Œè€Œä¸æ˜¯æŠ¥é”™ã€‚\nåœ¨çˆ¬å–è¿‡ç¨‹ä¸­ï¼Œæˆ‘é‡åˆ°äº†çˆ¬å–æˆåŠŸä½†æ˜¯å´å‘ç°æ•°æ®å¹¶æ²¡æœ‰å­˜å…¥æ•°æ®åº“ä¸­çš„æƒ…å†µï¼ŒæŸ¥é˜…èµ„æ–™åå‘ç°æ˜¯mysqlé”ä½äº†ï¼Œè¿›å…¥winç³»ç»Ÿé‡å¯MySQLæœåŠ¡å³å¯ã€‚\nè¿›è¡Œçˆ¬å–æµç¨‹ä»‹ç»çˆ¬å–çš„æ•´ä¸ªè¿‡ç¨‹ï¼šè¿›å…¥æ¯ä¸ªæ ‡ç­¾é¡µï¼Œè·å–è¯¥é¡µçš„20æœ¬ä¹¦çš„urlï¼Œå†è¿›å…¥æ¯æœ¬ä¹¦çš„urlè¿›è¡Œä¿¡æ¯çš„æå–\næå–æ ‡ç­¾\n\nè¿›å…¥æ ‡ç­¾é¡µæå–è¿™é¡µä¸­20æœ¬ä¹¦çš„url\n\néšåå°±æ˜¯è¿›å…¥ä¹¦ç±é¡µé¢çˆ¬å–æ•°æ®ã€‚\nç¼–å†™ç›¸å…³å‡½æ•°def crawl_tags(page):    &quot;&quot;&quot;è·å–æ¯ä¸ªæ ‡ç­¾ç½‘é¡µçš„ç¬¬pageé¡µ&quot;&quot;&quot;    url = &#x27;https://book.douban.com/tag/?view=type&amp;icn=index-sorttags-all&#x27;    res = visit(url)    html = etree.HTML(res.text)    tags = html.xpath(&#x27;//*[@id=&quot;content&quot;]//tr/td/a/text()&#x27;)    pages_url = [&#x27;https://book.douban.com/tag/&#x27; + tag + &#x27;?=&#x27; + str((page-1)*20) + &#x27;&amp;type=T&#x27; for tag in tags]    print(&#x27;å·²è·å–&#x27; + str(len(pages_url)) + &#x27;ä¸ªæ ‡ç­¾ç½‘é¡µ&#x27;)    return pages_url\n\ndef get_book_urls(tag_url):    &quot;&quot;&quot;è·å–æ¯ä¸ªæ ‡ç­¾ç½‘é¡µä¸­çš„ç¬¬ä¸€é¡µï¼Œ20æœ¬ä¹¦&quot;&quot;&quot;    l = set()    i = 20    try:        res = visit(tag_url)        html = etree.HTML(res.text)        books_urls = html.xpath(&#x27;//*[@id=&quot;subject_list&quot;]/ul//li/div[2]/h2/a/@href&#x27;)        for book_url in books_urls:            l.add(book_url)        print(&#x27;å·²è·å–%dæœ¬ä¹¦&#x27; % i)        i += 20    except Exception as e:        print(e)        print(&#x27;è¦åœä¸€ä¼š!ä¼‘æ¯2ç§’&#x27;)  # å› ä¸ºçˆ¬äº†ä¸€å®šæ•°æ®é‡åï¼Œä»£ç†ä¼šè·³å‡ºproxyerroré”™è¯¯ï¼Œåœä¸€ä¼šå³å¯        time.sleep(2)    return list(l)\n\nä¹‹å‰æ²¡try-exceptè¯­å¥æ€»æ˜¯çˆ¬ä¸€ä¼šå°±åœï¼Œéƒé—·æ­»æˆ‘äº†ã€‚è¿™ç§å†™æ³•æ˜¯æˆ‘é¡¿æ‚Ÿå‡ºæ¥çš„ï¼Œè¿™æ ·å†™ä¹‹åï¼ŒçœŸçš„æ˜¯é£å¿«åœ°çˆ¬ã€‚\nä¸‹é¢è¿˜ä¼šç”¨åˆ°è¿™æ ·çš„å†™æ³•\nä¸»å‡½æ•°\nif __name__ == &#x27;__main__&#x27;:    tags_url = crawl_tags(1)  # è·å–æ¯ä¸ªæ ‡ç­¾é¡µçš„ç¬¬ä¸€é¡µ    # æˆ‘ä»¬å¯ä»¥é€šè¿‡å¯¹crawl_tagsä¼ å…¥ä¸åŒçš„é¡µæ•°ï¼Œè·å–æ¯ä¸ªæ ‡ç­¾é¡µçš„ç¬¬né¡µ    for page in tags_url:        book_urls = get_book_urls(page)  # æŸä¸ªæ ‡ç­¾çš„ç¬¬ä¸€é¡µçš„ä¹¦é“¾æ¥        for book_url in book_urls:            try:                res = visit(book_url)  # å¯¹é‚£ä¸€é¡µçš„ä¸€æœ¬ä¹¦è¿›è¡Œè®¿é—®                book = CrawlBook(res)  # å»ºç«‹ä¸€ä¸ªä¹¦å¯¹è±¡ï¼Œdataå­˜æ”¾å…¶ä¿¡æ¯ï¼Œä»¥jsonå­˜å‚¨                save_to_mysql(book.data)  # å°†è¯¥ä¹¦ä¿¡æ¯æ’å…¥mysqlä¸­ï¼Œç»§ç»­ç¬¬äºŒæœ¬            except Exception as e:                print(e)                print(&#x27;æ­‡ä¸€ä¼šQAQï¼Œå°±2ç§’&#x27;)                time.sleep(2)    # æ¢åˆ°å¦å¤–ä¸€ä¸ªæ ‡ç­¾çš„ç¬¬1é¡µ\n\nçˆ¬å–è¿‡ç¨‹æˆªå›¾\nè¿™æ˜¯æˆ‘ä¿å­˜ä¸‹æ¥çš„æˆªå›¾ä¹‹ä¸€ï¼Œå¯è§ï¼Œå­˜å‚¨æ•°æ®æ—¶ç»å¸¸ä¼šé‡åˆ°ä¸€äº›æˆ‘ä»¬æ„å‘ä¸åˆ°çš„æŠ¥é”™ï¼Œæ‰€ä»¥å¼‚å¸¸å¤„ç†çœŸçš„å¾ˆé‡è¦å•Šï¼ï¼ï¼\nå°‘å¹´ï¼Œä¸€å®šè¦å­¦ä¼šç”¨try-exceptè¯­å¥å•Šï¼ï¼ï¼ä½ åˆšå¼€å§‹å­¦å¼‚å¸¸å¤„ç†è§‰å¾—æ²¡ä»€ä¹ˆç”¨ï¼Œç­‰ä½ é­å—è¿‡æ¯’æ‰“å°±çŸ¥é“æœ‰å¤šé‡è¦äº†ï¼ï¼ï¼\nè¿™æ˜¯æ•°æ®åº“ä¸­çš„éƒ¨åˆ†æ•°æ®ï¼ˆç”¨äº†navicatï¼‰\n\nä¸‹è½½ä¹¦ç±å›¾ç‰‡å› ä¸ºæˆ‘è€ƒæ ¸æœ‰ä¸€ä¸ªç•Œé¢è¦åšä¹¦ç±ä¿¡æ¯çš„å±•ç¤ºï¼Œè¦è´´ä¹¦çš„å°é¢å›¾ï¼Œæ‰€ä»¥è¿˜è¦ä¸‹è½½ä¸‹æ¥ã€‚\næˆ‘ä»¬æ•°æ®åº“ä¸­å­˜å‚¨çš„å­—æ®µé‡Œæœ‰å›¾ç‰‡é“¾æ¥ï¼ˆcover_urlï¼‰ï¼Œæˆ‘ä»¬æå–å‡ºæ¥ï¼Œå¯¹æ¯ä¸ªé“¾æ¥è¿›è¡Œè®¿é—®ï¼Œè¿›è¡Œå›¾ç‰‡çš„ä¸‹è½½ã€‚\nç›´æ¥è´´ä»£ç ï¼šï¼ˆvisitå‡½æ•°è·Ÿä¹‹å‰æ˜¯ä¸€æ ·çš„ï¼‰\nimport osif __name__ == &#x27;__main__&#x27;:    sql_f = &quot;SELECT * FROM books&quot; # é€‰å–æ‰€æœ‰ä¹¦    try:        cur.execute(sql_f)        results = cur.fetchall()  # è·å¾—åŒ¹é…ç»“æœ        columnDes = cur.description  # è·å–è¿æ¥å¯¹è±¡çš„æè¿°ä¿¡æ¯        columnNames = [columnDes[i][0] for i in range(len(columnDes))]  # è·å–åˆ—å        # å¾—åˆ°çš„resultsä¸ºäºŒç»´å…ƒç»„ï¼Œé€è¡Œå–å‡ºï¼Œè½¬åŒ–ä¸ºåˆ—è¡¨ï¼Œå†è½¬åŒ–ä¸ºdf        books_df = pd.DataFrame([list(i) for i in results], columns=columnNames)    except Exception as e:        print(e)    books_df = books_df.dropna(axis=0, subset=[&quot;cover_url&quot;])  # å»é™¤cover_urlæœ‰ç¼ºå¤±å€¼çš„è¡Œ    if &#x27;books_cover&#x27; in os.listdir(os.getcwd()):        pass    else:        os.mkdir(&#x27;books_cover&#x27;)  # åˆ›å»ºbooks_coverç›®å½•ï¼Œè´Ÿè´£å­˜æ”¾ä¹¦ç±å°é¢å›¾    os.chdir(&#x27;books_cover&#x27;)  # åˆ‡æ¢åˆ°books_coverç›®å½•    for i in range(len(books_df)):        try:            res = visit(books_df.iloc[i][10])  # è®¿é—®å›¾ç‰‡é“¾æ¥        except Exception as e:            print(e)            print(&quot;æ­‡ä¸€ä¼šå§QAQï¼Œå°±2ç§’&quot;)            time.sleep(2)        try:            print(&quot;æ­£åœ¨ä¿å­˜ç¬¬&quot; + str(i + 1) + &quot;å¼ å›¾ç‰‡...&quot;)            with open(books_df.iloc[i][0] + &#x27;.jpg&#x27;, &#x27;wb&#x27;) as f:                f.write(res.content)  # ä»¥ä¹¦åä¸ºæ–‡ä»¶åä¸‹è½½å›¾ç‰‡        except:            print(&#x27;ä¿å­˜å¤±è´¥!&#x27;)    conn.close()  # å…³é—­pythonä¸mysqlçš„è¿æ¥\n\nç¤ºä¾‹æˆªå›¾ï¼š\n\n\næ•´ä½“ä»£ç crawl_bookæ–‡ä»¶# åº“å¯¼å…¥éƒ¨åˆ†import refrom lxml import etreefrom bs4 import BeautifulSoupclass CrawlBook:    def __init__(self, res):        try:            self.soup = BeautifulSoup(res.text, &#x27;lxml&#x27;)  # åˆå§‹åŒ–            self.html = etree.HTML(res.text)  # åˆå§‹åŒ–            self.data = dict()  # ç”Ÿæˆä¸€ä¸ªç©ºå­—å…¸            self.get_book_name()            self.get_author()            self.get_many()            self.get_score()            self.get_rating_num()            self.get_content()            self.get_image()            self.get_readers()        except Exception as e:            self.data.setdefault(&#x27;author&#x27;, &#x27;&#x27;)            self.data.setdefault(&#x27;å‡ºç‰ˆç¤¾:&#x27;, &#x27;&#x27;)            self.data.setdefault(&#x27;å‡ºç‰ˆå¹´:&#x27;, &#x27;&#x27;)            self.data.setdefault(&#x27;é¡µæ•°:&#x27;, &#x27;0&#x27;)            self.data.setdefault(&#x27;å®šä»·:&#x27;, &#x27;&#x27;)            self.data.setdefault(&#x27;ISBN:&#x27;, &#x27;&#x27;)            self.data.setdefault(&#x27;score&#x27;, 0.0)            self.data.setdefault(&#x27;rating_num&#x27;, 0)            self.data.setdefault(&#x27;content_introduction&#x27;, &#x27;&#x27;)            self.data.setdefault(&#x27;readers&#x27;, &#x27;[]&#x27;)            print(e)    def get_book_name(self):        book_name = self.soup.find(name=&#x27;span&#x27;, attrs=&#123;&#x27;property&#x27;: &#x27;v:itemreviewed&#x27;&#125;).string        # æ‰¾åˆ°èŠ‚ç‚¹åä¸ºspanï¼Œå±æ€§propertyå€¼ä¸ºitemreviewdçš„èŠ‚ç‚¹ï¼Œ.stringè·å–å…¶æ–‡æœ¬å†…å®¹        self.data.setdefault(&#x27;book_name&#x27;, book_name)  # å°†å…¶æ·»åŠ åˆ°å­—å…¸ä¸­ï¼Œä¸‹é¢çš„è§£ææ–¹æ³•å¤§åŒå°å¼‚    def get_author(self):        author = self.soup.find(name=&#x27;span&#x27;, text=re.compile(&#x27;.*?ä½œè€….*?&#x27;)).next_sibling.next_sibling\\            .string.replace(&#x27;\\n&#x27;, &#x27;&#x27;).replace(&#x27; &#x27;, &#x27;&#x27;)        self.data.setdefault(&#x27;author&#x27;, author)    def get_many(self):        want_to_spider = [&#x27;å‡ºç‰ˆç¤¾:&#x27;, &#x27;å‡ºç‰ˆå¹´:&#x27;, &#x27;é¡µæ•°:&#x27;, &#x27;å®šä»·:&#x27;, &#x27;ISBN:&#x27;]        for i in self.soup.find_all(name=&#x27;span&#x27;, attrs=&#123;&#x27;class&#x27;: &#x27;pl&#x27;&#125;):            if i.string in want_to_spider:                self.data.setdefault(i.string, i.next_sibling.replace(&#x27; &#x27;, &#x27;&#x27;))    def get_score(self):        score = float(self.soup.find(name=&#x27;strong&#x27;, attrs=&#123;&#x27;property&#x27;: &#x27;v:average&#x27;&#125;).string)        self.data.setdefault(&#x27;score&#x27;, score)    def get_rating_num(self):        rating_num = int(self.soup.find(name=&#x27;span&#x27;, attrs=&#123;&#x27;property&#x27;: &#x27;v:votes&#x27;&#125;).string)        self.data.setdefault(&#x27;rating_num&#x27;, rating_num)    def get_content(self):        l = &#x27;&#x27;        try:            for i in self.soup.find(name=&#x27;div&#x27;, attrs=&#123;&#x27;class&#x27;: &#x27;intro&#x27;&#125;).contents:                l += str(i)            self.data.setdefault(&#x27;content_introduction&#x27;, l.strip())        except Exception as e:            print(e)            self.data.setdefault(&#x27;content_introduction&#x27;, &#x27;&#x27;)    def get_image(self):        image_url = self.soup.find(name=&#x27;img&#x27;, attrs=&#123;&#x27;rel&#x27;: &#x27;v:photo&#x27;&#125;)[&#x27;src&#x27;]  # è·å–èŠ‚ç‚¹çš„srcå±æ€§å€¼        self.data.setdefault(&#x27;cover_url&#x27;, image_url)    def get_readers(self):        readers = str(self.html.xpath(&#x27;//*[@id=&quot;collector&quot;]//div/div[2]/a/@href&#x27;))          # è¿™é‡Œç”¨çš„æ˜¯xpathçš„è§£ææ–¹æ³•ï¼Œè·å–æ‰€æœ‰å±æ€§å€¼ä¸ºcollectorä¸‹çš„æ‰€æœ‰divèŠ‚ç‚¹ä¸‹çš„ç¬¬äºŒä¸ªdivèŠ‚ç‚¹çš„aèŠ‚ç‚¹çš„hrefå±æ€§å€¼        self.data.setdefault(&#x27;readers&#x27;, readers)\n\ncrawlæ–‡ä»¶import randomimport timeimport requestsimport refrom lxml import etreefrom bs4 import BeautifulSoupfrom crawl_book import CrawlBookimport pymysqlconn = pymysql.connect(  # è¿æ¥æœ¬åœ°æ•°æ®åº“        host=&quot;localhost&quot;,        user=&quot;root&quot;,  # è¦å¡«root        password=&quot;htht0928&quot;,  # å¡«ä¸Šè‡ªå·±çš„å¯†ç         database=&quot;doubanbook&quot;,  # æ•°æ®åº“å        charset=&quot;utf8&quot;    )cur = conn.cursor()# è¯·æ±‚å¤´headers = [    &#123;        &#x27;User-Agent&#x27;: &#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36&#x27;,        &#x27;Connection&#x27;: &#x27;close&#x27;&#125;,    &#123;        &#x27;User-Agent&#x27;: &quot;Mozilla/5.0 (X11; U; Linux x86_64; zh-CN; rv:1.9.2.10) Gecko/20100922 Ubuntu/10.10 (maverick) Firefox/3.6.10&quot;,        &#x27;Connection&#x27;: &#x27;close&#x27;&#125;,    &#123;        &#x27;User-Agent&#x27;: &quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36 OPR/26.0.1656.60&quot;,        &#x27;Connection&#x27;: &#x27;close&#x27;&#125;,    &#123;        &#x27;User-Agent&#x27;: &quot;Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; .NET4.0E; QQBrowser/7.0.3698.400)&quot;,        &#x27;Connection&#x27;: &#x27;close&#x27;&#125;,    &#123;        &#x27;User-Agent&#x27;: &quot;Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; Trident/4.0; SV1; QQDownload 732; .NET4.0C; .NET4.0E; SE 2.X MetaSr 1.0)&quot;,        &#x27;Connection&#x27;: &#x27;close&#x27;&#125;,    &#123;&#x27;User-Agent&#x27;: &quot;Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko&quot;,        &#x27;Connection&#x27;: &#x27;close&#x27;&#125;,    &#123;        &#x27;User-Agent&#x27;: &quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Maxthon/4.4.3.4000 Chrome/30.0.1599.101 Safari/537.36&quot;,        &#x27;Connection&#x27;: &#x27;close&#x27;&#125;    ]# httpä»£ç†æ¥å…¥æœåŠ¡å™¨åœ°å€ç«¯å£proxyHost = &quot;http-proxy-t3.dobel.cn&quot;proxyPort = &quot;9180&quot;#è´¦å·å¯†ç proxyUser = &quot;HORACEC0JB9ONL0&quot;proxyPass = &quot;t7PG9y5o&quot;proxyMeta = &quot;http://%(user)s:%(pass)s@%(host)s:%(port)s&quot; % &#123;    &quot;host&quot; : proxyHost,    &quot;port&quot; : proxyPort,    &quot;user&quot; : proxyUser,    &quot;pass&quot; : proxyPass,&#125;proxies = &#123;    &quot;http&quot;  : proxyMeta,    &quot;https&quot; : proxyMeta,&#125;def visit(targetUrl):    &quot;&quot;&quot;è®¿é—®ç½‘å€ï¼Œè¿”å›å“åº”&quot;&quot;&quot;    session = requests.Session()    session.keep_alive = False    res = session.get(targetUrl, proxies=proxies, headers=random.choice(headers))    return resdef crawl_tags(page):    &quot;&quot;&quot;è·å–æ¯ä¸ªæ ‡ç­¾ç½‘é¡µçš„pageé¡µ&quot;&quot;&quot;    url = &#x27;https://book.douban.com/tag/?view=type&amp;icn=index-sorttags-all&#x27;    res = visit(url)    html = etree.HTML(res.text)    tags = html.xpath(&#x27;//*[@id=&quot;content&quot;]//tr/td/a/text()&#x27;)    pages_url = [&#x27;https://book.douban.com/tag/&#x27; + tag + &#x27;?=&#x27; + str((page-1)*20) + &#x27;&amp;type=T&#x27; for tag in tags]    print(&#x27;å·²è·å–&#x27; + str(len(pages_url)) + &#x27;ä¸ªæ ‡ç­¾ç½‘é¡µ&#x27;)    return pages_urldef get_book_urls(tag_url):    &quot;&quot;&quot;è·å–æ¯ä¸ªæ ‡ç­¾ç½‘é¡µä¸­çš„ç¬¬ä¸€é¡µï¼Œ20æœ¬ä¹¦&quot;&quot;&quot;    l = set()    i = 20    try:        res = visit(tag_url)        html = etree.HTML(res.text)        books_urls = html.xpath(&#x27;//*[@id=&quot;subject_list&quot;]/ul//li/div[2]/h2/a/@href&#x27;)        for book_url in books_urls:            l.add(book_url)        print(&#x27;å·²è·å–%dæœ¬ä¹¦&#x27; % i)        i += 20    except Exception as e:        print(e)        print(&#x27;è¦åœä¸€ä¼š!ä¼‘æ¯2ç§’&#x27;)        time.sleep(2)    return list(l)def save_to_mysql(data):    &quot;&quot;&quot;dataæ˜¯ä¹¦ç±çš„ä¿¡æ¯ï¼Œjsonæ ¼å¼ï¼Œè¦æ’å…¥åˆ°releaseè¿™ä¸ªè¡¨&quot;&quot;&quot;    book_name = data.get(&#x27;book_name&#x27;)    author = data.get(&#x27;author&#x27;)    press = data.get(&#x27;å‡ºç‰ˆç¤¾:&#x27;)    publishing_year = data.get(&#x27;å‡ºç‰ˆå¹´:&#x27;)    page_num = data.get(&#x27;é¡µæ•°:&#x27;)    price = data.get(&#x27;å®šä»·:&#x27;)    ISBN = data.get(&#x27;ISBN:&#x27;)    score = data.get(&#x27;score&#x27;)    rating_num = data.get(&#x27;rating_num&#x27;)    content_introduction = data.get(&#x27;content_introduction&#x27;)    cover_url = data.get(&#x27;cover_url&#x27;)    readers = data.get(&#x27;readers&#x27;)    insert_data = (book_name, author, press, publishing_year, score, rating_num, page_num, price, ISBN,                   content_introduction, cover_url, readers)    insert_sql = &quot;&quot;&quot;        INSERT INTO books(book_name, author, press, publishing_year, score, rating_num, page_num, price,        ISBN, content_introduction, cover_url, readers)        VALUES(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)    &quot;&quot;&quot;    try:        # æ‰§è¡Œsqlè¯­å¥        cur.execute(insert_sql, insert_data)        # æäº¤æ‰§è¡Œ        conn.commit()        print(&#x27;ã€Š&#x27; + book_name + &#x27;ã€‹&#x27; + &#x27;ä¿¡æ¯å·²å­˜å‚¨æˆåŠŸ!&#x27;)    except Exception as e:        print(e)        conn.rollback()        print(&#x27;å­˜å‚¨å¤±è´¥!&#x27;)if __name__ == &#x27;__main__&#x27;:    tags_url = crawl_tags(4)  # è·å–ç¬¬ä¸€é¡µ    for page in tags_url:        book_urls = get_book_urls(page)  # æŸä¸ªæ ‡ç­¾çš„ç¬¬ä¸€é¡µçš„ä¹¦é“¾æ¥        for book_url in book_urls:            try:                res = visit(book_url)  # å¯¹é‚£ä¸€é¡µçš„ä¸€æœ¬ä¹¦è¿›è¡Œè®¿é—®                book = CrawlBook(res)  # å»ºç«‹ä¸€ä¸ªä¹¦å¯¹è±¡ï¼Œdataå­˜æ”¾å…¶ä¿¡æ¯ï¼Œä»¥jsonå­˜å‚¨                save_to_mysql(book.data)  # å°†è¯¥ä¹¦ä¿¡æ¯æ’å…¥mysqlä¸­ï¼Œç»§ç»­ç¬¬äºŒæœ¬            except Exception as e:                print(e)                print(&#x27;æ­‡ä¸€ä¼šQAQï¼Œå°±2ç§’&#x27;)                time.sleep(3)    # æ¢åˆ°å¦å¤–ä¸€ä¸ªæ ‡ç­¾çš„ç¬¬1é¡µ    start = 20    for i in range(60):        new = start + i*20        url = &#x27;https://book.douban.com/tag/%E6%97%85%E8%A1%8C?start=&#x27; + str(new) + &#x27;&amp;type=T&#x27;        book_urls = get_book_urls(url)        for book_url in book_urls:            try:                res = visit(book_url)                book = CrawlBook(res)                save_to_mysql(book.data)            except Exception as e:                print(e)                print(&#x27;æ­‡ä¸€ä¼šQAQï¼Œå°±2ç§’&#x27;)                time.sleep(2)    print(&#x27;çˆ¬å–å®Œæˆ!&#x27;)    conn.close()  # å…³é—­è¿æ¥ï¼Œä¸ç„¶å¤šäº†ï¼Œæ•°æ®åº“ä¼šé”\n\ndownload_imageæ–‡ä»¶import timeimport pymysqlimport osimport requestsimport randomimport pandas as pdconn = pymysql.connect(  # è¿æ¥æœ¬åœ°æ•°æ®åº“        host=&quot;localhost&quot;,        user=&quot;root&quot;,  # è¦å¡«root        password=&quot;htht0928&quot;,  # å¡«ä¸Šè‡ªå·±çš„å¯†ç         database=&quot;doubanbook&quot;,  # æ•°æ®åº“å        charset=&quot;utf8&quot;    )cur = conn.cursor()# è¯·æ±‚å¤´headers = [    &#123;        &#x27;User-Agent&#x27;: &#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36&#x27;,        &#x27;Connection&#x27;: &#x27;close&#x27;&#125;,    &#123;        &#x27;User-Agent&#x27;: &quot;Mozilla/5.0 (X11; U; Linux x86_64; zh-CN; rv:1.9.2.10) Gecko/20100922 Ubuntu/10.10 (maverick) Firefox/3.6.10&quot;,        &#x27;Connection&#x27;: &#x27;close&#x27;&#125;,    &#123;        &#x27;User-Agent&#x27;: &quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36 OPR/26.0.1656.60&quot;,        &#x27;Connection&#x27;: &#x27;close&#x27;&#125;,    &#123;        &#x27;User-Agent&#x27;: &quot;Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; .NET4.0E; QQBrowser/7.0.3698.400)&quot;,        &#x27;Connection&#x27;: &#x27;close&#x27;&#125;,    &#123;        &#x27;User-Agent&#x27;: &quot;Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; Trident/4.0; SV1; QQDownload 732; .NET4.0C; .NET4.0E; SE 2.X MetaSr 1.0)&quot;,        &#x27;Connection&#x27;: &#x27;close&#x27;&#125;,    &#123;&#x27;User-Agent&#x27;: &quot;Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko&quot;,        &#x27;Connection&#x27;: &#x27;close&#x27;&#125;,    &#123;        &#x27;User-Agent&#x27;: &quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Maxthon/4.4.3.4000 Chrome/30.0.1599.101 Safari/537.36&quot;,        &#x27;Connection&#x27;: &#x27;close&#x27;&#125;    ]# httpä»£ç†æ¥å…¥æœåŠ¡å™¨åœ°å€ç«¯å£proxyHost = &quot;http-proxy-t3.dobel.cn&quot;proxyPort = &quot;9180&quot;#è´¦å·å¯†ç proxyUser = &quot;HORACEC0JB9ONL0&quot;proxyPass = &quot;t7PG9y5o&quot;proxyMeta = &quot;http://%(user)s:%(pass)s@%(host)s:%(port)s&quot; % &#123;    &quot;host&quot; : proxyHost,    &quot;port&quot; : proxyPort,    &quot;user&quot; : proxyUser,    &quot;pass&quot; : proxyPass,&#125;proxies = &#123;    &quot;http&quot;  : proxyMeta,    &quot;https&quot; : proxyMeta,&#125;def visit(targetUrl):    &quot;&quot;&quot;è®¿é—®ç½‘å€ï¼Œè¿”å›å“åº”&quot;&quot;&quot;    session = requests.Session()    session.keep_alive = False    res = session.get(targetUrl, proxies=proxies, headers=random.choice(headers))    return resif __name__ == &#x27;__main__&#x27;:    sql_f = &quot;SELECT * FROM books&quot;    try:        cur.execute(sql_f)        results = cur.fetchall()        columnDes = cur.description  # è·å–è¿æ¥å¯¹è±¡çš„æè¿°ä¿¡æ¯        columnNames = [columnDes[i][0] for i in range(len(columnDes))]  # è·å–åˆ—å        # å¾—åˆ°çš„resultsä¸ºäºŒç»´å…ƒç»„ï¼Œé€è¡Œå–å‡ºï¼Œè½¬åŒ–ä¸ºåˆ—è¡¨ï¼Œå†è½¬åŒ–ä¸ºdf        books_df = pd.DataFrame([list(i) for i in results], columns=columnNames)    except Exception as e:        print(e)    books_df = books_df.dropna(axis=0, subset=[&quot;cover_url&quot;])  # å»é™¤cover_urlæœ‰ç¼ºå¤±å€¼çš„è¡Œ    if &#x27;books_cover&#x27; in os.listdir(os.getcwd()):        pass    else:        os.mkdir(&#x27;books_cover&#x27;)    os.chdir(&#x27;books_cover&#x27;)    for i in range(len(books_df)):        try:            res = visit(books_df.iloc[i][10])        except Exception as e:            print(e)            print(&quot;æ­‡ä¸€ä¼šå§QAQï¼Œå°±2ç§’&quot;)            time.sleep(2)        try:            print(&quot;æ­£åœ¨ä¿å­˜ç¬¬&quot; + str(i + 1) + &quot;å¼ å›¾ç‰‡...&quot;)            with open(books_df.iloc[i][0] + &#x27;.jpg&#x27;, &#x27;wb&#x27;) as f:                f.write(res.content)        except:            print(&#x27;ä¿å­˜å¤±è´¥!&#x27;)    conn.close()\n\n\n\næ€»ç»“è¿™æ˜¯æˆ‘5.14ä¸€å¤©çš„çˆ¬è™«è¿‡ç¨‹ï¼ˆä¸€å‘¨åçš„å›é¡¾ï¼‰â€¦è¿˜çœŸæ˜¯äººä¸é€¼è‡ªå·±ä¸€æŠŠï¼Œå°±ä¸çŸ¥é“è‡ªå·±çš„æ½œåŠ›æœ‰å¤šå¤§ã€‚\nè¿™æ˜¯ä»£ç†å¸®æˆ‘ç»Ÿè®¡æˆ‘ä¸€å¤©çš„è¯·æ±‚æ¬¡æ•°ï¼Œ1w8ï¼Œæˆ‘ä¹Ÿæ²¡æƒ³åˆ°hhh\n\nå…¶ä¸­é‡åˆ°äº†å¾ˆå¤šçš„å›°éš¾ï¼Œæ•°æ®æ’å…¥é—®é¢˜ï¼ŒæŠ¥é”™proxyerrorï¼Œmysqlé”ä½äº†â€¦æ‰€å¹¸éƒ½è§£å†³äº†\nè§£å†³çš„æ–¹å¼æˆ–æ˜¯æŸ¥é˜…èµ„æ–™ï¼Œæˆ–æ˜¯çµå…‰ä¹ç°â€¦\né‚£ä¸€å¤©å¤ªç´¯äº†ï¼ŒçœŸçš„å¤ªç´¯äº†ï¼Œå‡ºç°é—®é¢˜-&gt;è§£å†³é—®é¢˜-&gt;å‡ºç°é—®é¢˜-&gt;è§£å†³é—®é¢˜-&gt;â€¦\næ„Ÿè°¢æˆ‘çš„å¥½æœ‹å‹æ„¿æ„é™ªæˆ‘èŠå¤©ï¼ˆå½“æˆ‘çš„æ–‡ä»¶ä¼ è¾“åŠ©æ‰‹ï¼‰ï¼Œåœ¨æˆ‘ä½è½çš„æ—¶å€™ç»™äºˆæˆ‘ç²¾ç¥ä¸Šçš„é¼“åŠ±\n\né¾™å“¥ï¼Œæˆ‘æ˜¯ä½ çš„ç²‰ä¸å•Šï¼ï¼ˆé£è¸¢é£æ‰‘ï¼‰\né‚£ä¹ˆï¼Œæ­¤æ¬¡çš„çˆ¬è™«å›é¡¾ç»“æŸğŸ”šå•¦ã€‚\n","categories":["python"],"tags":["çˆ¬è™«"]},{"title":"æ’ä»¶aplayerçš„ä½¿ç”¨","url":"/2021/06/11/%E6%8F%92%E4%BB%B6aplayer%E7%9A%84%E4%BD%BF%E7%94%A8/","content":"githubæ–‡æ¡£ï¼šhttps://github.com/MoePlayer/hexo-tag-aplayer/blob/master/docs/README-zh_cn.md\næ•²å¦‚ä¸‹å‘½ä»¤è¿›è¡Œaplayeræ’ä»¶çš„å®‰è£…\nnpm install --save hexo-tag-aplayer\n\næ­¤å¤„ä½¿ç”¨çš„æ˜¯MetingJSã€‚MetingJS æ˜¯åŸºäºMeting API çš„ APlayer è¡ç”Ÿæ’­æ”¾å™¨ï¼Œå¼•å…¥ MetingJS åï¼Œæ’­æ”¾å™¨å°†æ”¯æŒå¯¹äº QQéŸ³ä¹ã€ç½‘æ˜“äº‘éŸ³ä¹ã€è™¾ç±³ã€é…·ç‹—ã€ç™¾åº¦ç­‰å¹³å°çš„éŸ³ä¹æ’­æ”¾ã€‚\nå¦‚è¦ä½¿ç”¨è¯¥åŠŸèƒ½ï¼Œkeepä¸»é¢˜é…ç½®æ–‡ä»¶è¯·ä¸è¦å¯ç”¨pjaxï¼Œå³pjax: falseï¼Œå¦åˆ™æ— æ³•ä½¿ç”¨ã€‚\nä»¥ç½‘æ˜“äº‘éŸ³ä¹ä¸ŠèŠ±ã«äº¡éœŠè¿™é¦–éŸ³ä¹ä¸ºä¾‹ï¼š\n{% meting \"1442466883\" \"netease\" \"song\" %}\n\n\n    \n\n\n\næœ‰å…³ {% meting %} çš„é€‰é¡¹åˆ—è¡¨å¦‚ä¸‹:\n\n\n\né€‰é¡¹\né»˜è®¤å€¼\næè¿°\n\n\n\nid\nå¿…é¡»å€¼\næ­Œæ›² id / æ’­æ”¾åˆ—è¡¨ id / ç›¸å†Œ id / æœç´¢å…³é”®å­—\n\n\nserver\nå¿…é¡»å€¼\néŸ³ä¹å¹³å°: netease, tencent, kugou, xiami, baidu\n\n\ntype\nå¿…é¡»å€¼\nsong, playlist, album, search, artist\n\n\nfixed\nfalse\nå¼€å¯å›ºå®šæ¨¡å¼\n\n\nmini\nfalse\nå¼€å¯è¿·ä½ æ¨¡å¼\n\n\nloop\nall\nåˆ—è¡¨å¾ªç¯æ¨¡å¼ï¼šall, one,none\n\n\norder\nlist\nåˆ—è¡¨æ’­æ”¾æ¨¡å¼ï¼š list, random\n\n\nvolume\n0.7\næ’­æ”¾å™¨éŸ³é‡\n\n\nlrctype\n0\næ­Œè¯æ ¼å¼ç±»å‹\n\n\nlistfolded\nfalse\næŒ‡å®šéŸ³ä¹æ’­æ”¾åˆ—è¡¨æ˜¯å¦æŠ˜å \n\n\nstoragename\nmetingjs\nLocalStorage ä¸­å­˜å‚¨æ’­æ”¾å™¨è®¾å®šçš„é”®å\n\n\nautoplay\ntrue\nè‡ªåŠ¨æ’­æ”¾ï¼Œç§»åŠ¨ç«¯æµè§ˆå™¨æš‚æ—¶ä¸æ”¯æŒæ­¤åŠŸèƒ½\n\n\nmutex\ntrue\nè¯¥é€‰é¡¹å¼€å¯æ—¶ï¼Œå¦‚æœåŒé¡µé¢æœ‰å…¶ä»– aplayer æ’­æ”¾ï¼Œè¯¥æ’­æ”¾å™¨ä¼šæš‚åœ\n\n\nlistmaxheight\n340px\næ’­æ”¾åˆ—è¡¨çš„æœ€å¤§é•¿åº¦\n\n\npreload\nauto\néŸ³ä¹æ–‡ä»¶é¢„è½½å…¥æ¨¡å¼ï¼Œå¯é€‰é¡¹ï¼š none, metadata, auto\n\n\ntheme\n#ad7a86\næ’­æ”¾å™¨é£æ ¼è‰²å½©è®¾ç½®\n\n\nè¯•è¯•æˆ‘è‡ªå·±QQéŸ³ä¹çš„æ­Œå•ï¼Œå› ä¸ºæ˜¯æ­Œå•ï¼Œæ‰€ä»¥è¦å†™playlist\n{% meting \"7855838128\" \"tencent\" \"playlist\" %}\n\n    \n\n\n\nä½¿ç”¨mmediaæ’ä»¶\n.bbplayer{width: 100%; max-width: 850px; margin: auto} document.getElementById(\"mmedia-bhCKFcxUmdXBOQSh\").style.height=document.getElementById(\"mmedia-bhCKFcxUmdXBOQSh\").scrollWidth*0.76+\"px\";\n    window.onresize = function(){\n      document.getElementById(\"mmedia-bhCKFcxUmdXBOQSh\").style.height=document.getElementById(\"mmedia-bhCKFcxUmdXBOQSh\").scrollWidth*0.76+\"px\";\n    }; \n\n{% mmedia \"bilibili\" \"bvid:BV1B5411M7Zf\" %}\n","categories":["hexo"],"tags":["æ’ä»¶"]},{"title":"é™ç»´ç®—æ³•","url":"/2021/08/04/%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95/","content":"é™ç»´ç®—æ³•å‚è€ƒèµ„æ–™ï¼šã€æœºå™¨å­¦ä¹ ã€‘ã€ç™½æ¿æ¨å¯¼ç³»åˆ—ã€‘\nå¼•å…¥èƒŒæ™¯é™ç»´ï¼ŒDimensionality Reduction\nåœ¨æœºå™¨å­¦ä¹ è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬æ›´å…³æ³¨çš„æ˜¯æ³›åŒ–è¯¯å·®ï¼Œè€Œä¸æ˜¯è®­ç»ƒè¯¯å·®ã€‚\nè€Œè¿‡æ‹Ÿåˆé—®é¢˜è§£å†³çš„æ–¹æ³•ï¼š\n\næ•°æ®é‡æå‡\næ­£åˆ™å“ˆ\né™ç»´\n\nä¸ºä»€ä¹ˆé™ç»´ä¼šè§£å†³è¿‡æ‹Ÿåˆé—®é¢˜å‘¢ï¼Ÿåˆæˆ–è€…æ¢ä¸€ç§é—®æ³•ï¼šä¸ºä»€ä¹ˆç»´åº¦é«˜ä¼šé€ æˆä¸€ä¸ªè¿‡æ‹Ÿåˆå‘¢ï¼Ÿ\næˆ‘ä»¬å¯ä»¥è¿™æ ·æƒ³ï¼šæ¯å¢åŠ ä¸€ä¸ªç»´åº¦ï¼Œé‚£æˆ‘éœ€è¦ç”¨æ¥coveræ•´ä¸ªæ ·æœ¬ç©ºé—´çš„é‡æ˜¯ä»¥æŒ‡æ•°çº§åˆ«å¢é•¿çš„ï¼ˆå‡è®¾æ¯ä¸ªç‰¹å¾éƒ½æ˜¯äºŒå€¼çš„ï¼Œç°æœ‰nä¸ªç‰¹å¾ï¼Œå†å¢åŠ ä¸€ä¸ªç‰¹å¾ï¼Œé‚£æ ·æœ¬ç©ºé—´å°±å¢åŠ äº†â€‹ä¸ªç‚¹ï¼Œé‚£å°±æ›´åˆ«è¯´å¤šå€¼çš„ç‰¹å¾äº†ï¼‰\nå‡ ä½•è§’åº¦å¼•å…¥äºŒç»´ä¸‹ï¼Œè®¾æ­£æ–¹å½¢è¾¹é•¿ä¸º1ï¼Œé‚£ä¹ˆä»–çš„é¢ç§¯åˆ™ä¸º1ï¼Œå…¶ä¸­åŒ…å«ä¸€ä¸ªå†…åˆ‡åœ†ï¼Œé‚£ä¹ˆä»–çš„é¢ç§¯ä¸º\nä¸‰ç»´ä¸‹ï¼Œè®¾æ­£æ–¹ä½“è¾¹é•¿ä¸º1ï¼Œé‚£ä¹ˆä»–çš„ä½“ç§¯ä¸º1ï¼Œå…¶ä¸­åŒ…å«ä¸€ä¸ªå†…åˆ‡çƒï¼Œé‚£ä¹ˆä»–çš„ä½“ç§¯ä¸º\nä¸ºäº†ä¹¦å†™æ–¹ä¾¿ï¼Œæˆ‘ä»¬ä»¤å¸¸æ•°ï¼Œåˆ™ä¸‰ç»´ä¸‹çš„ä½“ç§¯ä¸º\né‚£ä¹ˆï¼Œæˆ‘ä»¬æ¨å¹¿åˆ°Dç»´ç©ºé—´ï¼Œè¶…ç«‹æ–¹ä½“å†…å«ä¸€ä¸ªè¶…çƒä½“ï¼Œè¯¥è¶…çƒä½“ä½“ç§¯åˆ™ä¸ºâ€‹ï¼Œæ˜“å¾—ä¹Ÿå°±æ˜¯è¯´å½“ç»´åº¦ä¸æ–­å¢åŠ è¿™ä¸ªè¶…çƒä½“è¿‘ä¹ä¸€ä¸ªç©ºç‚¹ï¼ˆæœ‰ç‚¹åç›´è§‰ï¼‰ï¼Œé‚£ä¹ˆå¾ˆå®¹æ˜“æƒ³åˆ°ï¼Œæ•°æ®ä¼šè¾ƒå®¹æ˜“åˆ†å¸ƒåœ¨è¯¥çƒå¤–ï¼Œä¹Ÿå°±æ˜¯åˆ†å¸ƒåœ¨è¾¹ç¼˜ï¼Œä¹Ÿå°±å¸¦æ¥äº†æ•°æ®ç¨€ç–æ€§é—®é¢˜\n\nåˆ†ç±»\nç›´æ¥é™ç»´ï¼Œå³ç‰¹å¾é€‰æ‹©ï¼Œé€‰æ‹©å‡ºè‡ªå·±è§‰å¾—é‡è¦çš„ç‰¹å¾\nçº¿æ€§é™ç»´ï¼šPCAï¼ŒMDSç­‰\néçº¿æ€§é™ç»´ï¼šæµå½¢å­¦ä¹ ï¼ŒåŒ…æ‹¬ Isomapï¼ŒLLE ç­‰\n\né¢„å¤‡çŸ¥è¯†å‡è®¾æ•°æ®é›†Xä¸ºNÃ—På½¢çŠ¶ï¼Œå³Nä¸ªæ ·æœ¬ï¼ŒPä¸ªç‰¹å¾ï¼Œé‚£ä¹ˆä¸€ä¸ªæ ·æœ¬åˆ™ä¸ºpç»´å‘é‡\n\nå¤šç»´ä¸‹ï¼Œæ ·æœ¬å‡å€¼â€‹â€‹ï¼ˆå¼ï¼‰æ˜¾ç„¶ï¼Œæ ·æœ¬å‡å€¼ä¸ºçš„pç»´å‘é‡\nåæ–¹å·®çŸ©é˜µSï¼ˆå¼ï¼‰ä¸éš¾çœ‹å‡ºï¼Œåæ–¹å·®çŸ©é˜µSä¸ºçš„çŸ©é˜µ\næ ¹æ®ä¹‹å‰çš„ç»éªŒï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡çº¿ä»£çš„çŸ¥è¯†å°†è¿åŠ å·å»æ‰\n\nç”±äºåªæ˜¯å·®äº†ä¸€ä¸ªè½¬ç½®ï¼Œæ‰€ä»¥ä¸‹é¢æˆ‘åªè®¨è®ºå·¦åŠè¾¹çš„å¼å­ï¼Œç»§ç»­è¿›è¡ŒåŒ–ç®€ï¼ˆå¼ï¼‰å…¶ä¸­ï¼Œä¸ºå½¢çŠ¶ä¸ºçš„å…¨ä¸º1çš„åˆ—å‘é‡ï¼Œå³ç”±å¼1å¯ç»§ç»­å¯¹å¼3è¿›è¡ŒåŒ–ç®€\nå¼ï¼‰\nä¸éš¾å¾—å‡ºå½¢çŠ¶ä¸ºï¼Œæˆ‘ä»¬å°†å…¶è®°ä½œï¼Œç§°ä½œä¸­å¿ƒçŸ©é˜µï¼ˆcentering matrixï¼‰\näºæ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥å°†å¼2åŒ–ç®€æˆè¯¥ä¸­å¿ƒçŸ©é˜µHæœ‰ä¸€ä¸ªè‰¯å¥½çš„æ€§è´¨ï¼Œâ€‹ï¼ˆè¯»è€…å¯ä»¥è‡ªå·±è¯•ç€æ¨å¯¼ä¸€ä¸‹ï¼‰ï¼Œè¿›è€Œæ¨å¯¼å‡º\nå› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥è¿›ä¸€æ­¥åŒ–ç®€å¼å­ï¼Œå°†å¼2åŒ–æˆï¼ˆå¼ï¼‰\nPCAä¸»æˆåˆ†åˆ†æ\nç»å…¸çš„ä¸»æˆåˆ†åˆ†æï¼Œé¡ºå£æºœæ€»ç»“ä¸ºä¸€ä¸ªä¸­å¿ƒï¼Œä¸¤ä¸ªåŸºæœ¬ç‚¹\nä¸€ä¸ªä¸­å¿ƒå°†ä¸€ç»„å¯èƒ½çº¿æ€§ç›¸å…³çš„å˜é‡é€šè¿‡çº¿æ€§å˜æ¢å˜æ¢æˆä¸€ç»„çº¿æ€§æ— å…³çš„å˜é‡\næ¢å¥è¯è¯´å°±æ˜¯å¯¹åŸå§‹ç‰¹å¾ç©ºé—´çš„é‡æ„ï¼Œè®©ç‰¹å¾æ­£äº¤å˜æ¢ä¸€ç»„çº¿æ€§æ— å…³çš„åŸº\nä¸¤ä¸ªåŸºæœ¬ç‚¹\næœ€å¤§æŠ•å½±æ–¹å·® \næœ€å°é‡æ„è·ç¦»\n\nä¸¤ä¸ªæ˜¯åŒä¸€ä¸ªä¸œè¥¿\nå›¾æºè‡ªæèˆªè€å¸ˆçš„ã€Šç»Ÿè®¡å­¦ä¹ æ–¹æ³•ã€‹ï¼Œçº¢æ¡†éƒ¨åˆ†æ˜¯PCAçš„é€‰æ‹©æ–°åŸºçš„ä¸»è¦æ€æƒ³\n\nå› æ­¤ï¼Œæˆ‘ä»¬å°±éœ€è¦çŸ¥é“è¯¥æŠ•å½±æ–¹å·®æ€ä¹ˆè¡¨ç¤ºå‡ºæ¥å¹¶æœ€å¤§åŒ–\næœ€å¤§æŠ•å½±æ–¹å·®é¦–å…ˆï¼Œæˆ‘ä»¬æ‹¿åˆ°æ•°æ®åï¼Œç¬¬ä¸€æ­¥è¦åšæ•°æ®ä¸­å¿ƒåŒ–ï¼Œæ•°å­¦è¡¨è¾¾ä¸º\næŠ•å½±çš„è¡¨ç¤ºåœ¨é«˜ä¸­æ•°å­¦ä¸­ï¼Œå‘é‡çš„æ•°é‡ç§¯é‚£ä¹ˆåœ¨ä¸Šçš„æŠ•å½±â€‹ä¸º\nå¦‚æœæˆ‘ä»¬**ä»¤è¢«æŠ•å½±å‘é‡çš„æ¨¡**ï¼Œé‚£ä¹ˆåˆ™æ°å¥½æ˜¯åœ¨ä¸Šçš„æŠ•å½±\nå¤šç»´ä¸­åœ¨â€‹ä¸Šçš„æŠ•å½±åˆ™è¡¨ç¤ºä¸º\næŠ•å½±æ–¹å·®æˆ‘ä»¬è®°æ–°åŸºä¸ºï¼Œé‚£ä¹ˆä¸€ä¸ªæ ·æœ¬ç‚¹çš„åœ¨ä¸Šçš„æŠ•å½±ä¸ºé‚£ä¹ˆæ‰€æœ‰æ ·æœ¬ç‚¹çš„æŠ•å½±æ–¹å·®å’Œåœ¨çš„çº¦æŸæ¡ä»¶ä¸‹è®°ä¸ºï¼ˆäºŒèŒƒå¼=1è·Ÿå‘é‡å†…ç§¯=1æ˜¯ç­‰ä»·çš„ï¼Œæ‰€ä»¥çº¦æŸæ¡ä»¶æ¢äº†ä¸€ä¸‹ï¼‰\n\nä¸éš¾å‘ç°ä¸­é—´é‚£é¡¹å’Œå¼2å¾ˆåƒï¼Œåªå·®äº†ä¸€ä¸ª\næ‰€ä»¥æˆ‘ä»¬å¯ä»¥è¿‘ä¼¼åœ°æŠŠå†™æˆé‚£ä¹ˆç°åœ¨çš„é—®é¢˜å°±è½¬åŒ–ä¸ºäº†\n\näºæ˜¯é‡‡ç”¨æ‹‰æ ¼æœ—æ—¥ä¹˜æ•°æ³•ï¼Œå°†çº¦æŸé—®é¢˜åŒ–ä¸ºæ— çº¦æŸé—®é¢˜é‚£ä¹ˆå¯¹å…¶æ±‚åå¯¼ï¼Œä»¤å…¶=0å¾—Sä¸ºçŸ©é˜µï¼Œä¸ºå®æ•°å€¼ï¼Œæˆ‘ä»¬ä¸éš¾çœ‹å‡ºï¼Œâ€‹ä¸ºåæ–¹å·®çŸ©é˜µSçš„ç‰¹å¾å€¼ï¼Œä¸ºå¯¹åº”çš„ç‰¹å¾å‘é‡\næœ€å°é‡æ„ä»£ä»·ä¸æƒ³æ‰“å…¬å¼äº†ï¼Œç›´æ¥åœ¨çº¸ä¸Šå†™äº†ï¼Œç›´æ¥çœ‹å›¾æŠŠ\n\né‚£ä¹ˆç°åœ¨çš„é—®é¢˜ä¸º\n\nå®é™…ä¸Šæˆ‘ä»¬å¯ä»¥å¯¹æ¯ä¸ªåŸºå•ç‹¬è¿›è¡Œæ‹‰æ ¼æœ—æ—¥ä¹˜æ•°æ³•\n\nç®—æ³•å®ç°æ­¥éª¤å‚è€ƒèµ„æ–™ï¼šhttps://zhuanlan.zhihu.com/p/77151308\nè®¾æœ‰ m æ¡ n ç»´æ•°æ®ã€‚\n\nå°†åŸå§‹æ•°æ®æŒ‰åˆ—ç»„æˆ n è¡Œ m åˆ—çŸ©é˜µ Xï¼›\nå°† X çš„æ¯ä¸€è¡Œè¿›è¡Œé›¶å‡å€¼åŒ–ï¼Œå³å‡å»è¿™ä¸€è¡Œçš„å‡å€¼ï¼›\næ±‚å‡ºåæ–¹å·®çŸ©é˜µ  ï¼›\næ±‚å‡ºåæ–¹å·®çŸ©é˜µçš„ç‰¹å¾å€¼åŠå¯¹åº”çš„ç‰¹å¾å‘é‡ï¼›\nå°†ç‰¹å¾å‘é‡æŒ‰å¯¹åº”ç‰¹å¾å€¼å¤§å°ä»ä¸Šåˆ°ä¸‹æŒ‰è¡Œæ’åˆ—æˆçŸ©é˜µï¼Œå–å‰ k è¡Œç»„æˆçŸ©é˜µ Pï¼›\n å³ä¸ºé™ç»´åˆ° k ç»´åçš„æ•°æ®ã€‚\n\nç¨å¾®æœ‰ç‚¹å¡çš„æ­¥éª¤æ˜¯5ï¼Œå…¶ä»–å€’ä¹Ÿæ²¡æœ‰ä»€ä¹ˆ\nä»£ç å®ç°import numpy as npclass PCA:    def __init__(self, X):        \"\"\"è¾“å…¥ä¸€ä¸ªnumpyæˆ–pandasçš„ç‰¹å¾çŸ©é˜µ\"\"\"        self.X = np.array(X).T        self.n, self.m = self.X.shape        self.equalization()        self.get_P()    def equalization(self):        \"\"\"æ•°æ®å‡å€¼åŒ–\"\"\"        for i in range(self.n):            self.X[i] = self.X[i] - self.X[i].mean()    def get_P(self):        \"\"\"æ±‚å‡ºçŸ©é˜µP\"\"\"        C = (1/self.m)*np.dot(self.X, self.X.T)        w, v = np.linalg.eig(C)        # wæ˜¯ç‰¹å¾å€¼ï¼Œvæ˜¯ç‰¹å¾å€¼å¯¹åº”çš„ç‰¹å¾å‘é‡æ’åˆ—è€Œæˆçš„çŸ©é˜µ        fea_rank_index = np.argsort(w)  # è¿”å›çš„æ˜¯ä¸€ä¸ªæŒ‡æ˜ç‰¹å¾å€¼ä»å°åˆ°å¤§æ’åºçš„ç´¢å¼•        column = len(w)        pre_P = v[fea_rank_index[0]].reshape(-1, column)        for i in fea_rank_index[1:]:            # æ ¹æ®ç‰¹å¾å€¼å¤§å°æŠŠå¯¹åº”çš„ç‰¹å¾å‘é‡æ‹¼æ¥ä¸Šå»            pre_P = np.concatenate([pre_P, v[fea_rank_index[i]].reshape(-1, column)])        self.pre_P = pre_P    def fit(self, k: int):        # è¿”å›é™åˆ°kç»´åçš„æ•°æ®        Y = np.dot(self.pre_P[:k], self.X)        return Y.T\n\nç®—æ³•è¯„ä¼°å»ç½‘ä¸ŠæŸ¥äº†ä¸€ä¸‹ï¼Œé™ç»´ç®—æ³•æ²¡æœ‰ä¸€ä¸ªå›ºå®šçš„é‡åŒ–æŒ‡æ ‡æ¥è¯„ä¼°ï¼Œåªèƒ½é€šè¿‡æœ€ç»ˆæ•ˆæœæ¥åˆ¤æ–­ï¼ˆæ¯”å¦‚åˆ†ç±»ä»»åŠ¡ä¸­ï¼Œé™ç»´åçš„å‡†ç¡®ç‡ï¼ŒæŸ¥å…¨ç‡æ˜¯å¦æå‡ï¼‰\näºæ˜¯æˆ‘é‡‡ç”¨ä¹³è…ºç™Œæ•°æ®é›†åˆ†ç±»ä»»åŠ¡æ¥åšä¸€ä¸‹é™ç»´çš„è¯„ä¼°\nfrom sklearn.datasets import load_breast_cancer  # ä¹³è…ºç™Œæ•°æ®é›†from sklearn.model_selection import train_test_split  # ç•™å‡ºæ³•from sklearn.linear_model import LogisticRegressionfrom sklearn.metrics import confusion_matrix # æ··æ·†çŸ©é˜µimport PCAdata = load_breast_cancer()X = data['data']Y = data['target'].reshape(-1, 1)  # é˜²æ­¢ä¸€ä¸ªå¥‡æ€ªçš„Bugmethod = PCA.PCA(X)X_pca = method.fit(25) # é™æˆ25ç»´x_train, x_test, y_train, y_test = train_test_split(X_pca, Y, test_size=0.2)  # åˆ’åˆ†æ•°æ®é›†skmodel = LogisticRegression(max_iter=2000)skmodel.fit(x_train, y_train)y_predict = skmodel.predict(x_test)test_score = skmodel.score(x_test, y_test)tn, fp, fn, tp = confusion_matrix(y_true=y_test, y_pred=y_predict).ravel()print(\"â€”â€”é™ç»´åâ€”â€”\")print(\"å‡†ç¡®ç‡ï¼š\" + str(test_score))print(\"æŸ¥å‡†ç‡Pï¼š\" + str(tp/(tp+fp)))print(\"æŸ¥å…¨ç‡Rï¼š\" + str(tp/(tp+fn)))x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)  # åˆ’åˆ†æ•°æ®é›†skmodel.fit(x_train, y_train)y_predict = skmodel.predict(x_test)test_score = skmodel.score(x_test, y_test)tn, fp, fn, tp = confusion_matrix(y_true=y_test, y_pred=y_predict).ravel()print(\"â€”â€”é™ç»´å‰â€”â€”\")print(\"å‡†ç¡®ç‡ï¼š\" + str(test_score))print(\"æŸ¥å‡†ç‡Pï¼š\" + str(tp/(tp+fp)))print(\"æŸ¥å…¨ç‡Rï¼š\" + str(tp/(tp+fn)))\n\nè¿™æ˜¯ä¸ºæ•°ä¸å¤šé™åˆ°25ç»´åï¼Œé™ç»´åæ•ˆæœæ¯”é™ç»´å‰æ•ˆæœå¥½çš„ä¸€æ¬¡\n\næˆ‘è¿˜æ‰“ç®—ç”»ä¸€ä¸ªå›¾ï¼Œç”»å‡ºå¯¹äºä¹³è…ºç™Œæ•°æ®é›†é™åˆ°å¤šå°‘ç»´æ•ˆæœï¼ˆå¯ä»¥æ˜¯å‡†ç¡®ç‡ï¼ŒæŸ¥å‡†ç‡ï¼ŒæŸ¥å…¨ç‡ï¼‰ä¼šæœ€å¥½ï¼Ÿ\n\nå‡†ç¡®ç‡\n\n\n\næŸ¥å‡†ç‡P\n\n\n\næŸ¥å…¨ç‡\n\n\nä¸‰ä¸ªå›¾åˆ†å¼€ç”»ä¼¼ä¹å¤ªéº»çƒ¦äº†ï¼Œè¯•ç€ä¸€èµ·ç”»ï¼Ÿ\nå…¶ä¸­ï¼Œçº¢è‰²ä¸ºå‡†ç¡®ç‡ï¼Œç»¿è‰²ä¸ºæŸ¥å‡†ç‡ï¼Œè“è‰²ä¸ºæŸ¥å…¨ç‡\n\nfrom sklearn.datasets import load_breast_cancer  # ä¹³è…ºç™Œæ•°æ®é›†from sklearn.model_selection import train_test_split  # ç•™å‡ºæ³•from sklearn.linear_model import LogisticRegressionfrom sklearn.metrics import confusion_matrix # æ··æ·†çŸ©é˜µimport PCAimport matplotlib.pyplot as pltfrom pylab import mplmpl.rcParams['font.sans-serif'] = ['FangSong']  # æŒ‡å®šé»˜è®¤å­—ä½“mpl.rcParams['axes.unicode_minus'] = False # è§£å†³ä¿å­˜å›¾åƒæ˜¯è´Ÿå·'-'æ˜¾ç¤ºä¸ºæ–¹å—çš„é—®é¢˜data = load_breast_cancer()X = data['data']Y = data['target'].reshape(-1, 1)  # é˜²æ­¢ä¸€ä¸ªå¥‡æ€ªçš„Bugmethod = PCA.PCA(X)l = list(range(10, 30))accuracy = []P = []R = []for i in l:    X_pca = method.fit(i) # é™æˆiç»´    x_train, x_test, y_train, y_test = train_test_split(X_pca, Y, test_size=0.2)  # åˆ’åˆ†æ•°æ®é›†    skmodel = LogisticRegression(max_iter=5000)    skmodel.fit(x_train, y_train)    y_predict = skmodel.predict(x_test)    test_score = skmodel.score(x_test, y_test)    tn, fp, fn, tp = confusion_matrix(y_true=y_test, y_pred=y_predict).ravel()    accuracy.append(test_score)    P.append(tp/(tp+fp))    R.append(tp/(tp+fn))plt.plot(l, accuracy, color=\"r\", marker=\"o\")plt.plot(l, P, color=\"g\", marker=\"+\")plt.plot(l, R, color=\"b\", marker=\"*\")plt.xlabel('ç»´æ•°')plt.ylabel('è¯„ä»·æ•ˆæœ')plt.show()\n\næ€§è´¨\nç¼“è§£ç»´åº¦ç¾éš¾ï¼šPCA ç®—æ³•é€šè¿‡èˆå»ä¸€éƒ¨åˆ†ä¿¡æ¯ä¹‹åèƒ½ä½¿å¾—æ ·æœ¬çš„é‡‡æ ·å¯†åº¦å¢å¤§ï¼ˆå› ä¸ºç»´æ•°é™ä½äº†ï¼‰ï¼Œè¿™æ˜¯ç¼“è§£ç»´åº¦ç¾éš¾çš„é‡è¦æ‰‹æ®µï¼›\né™å™ªï¼šå½“æ•°æ®å—åˆ°å™ªå£°å½±å“æ—¶ï¼Œæœ€å°ç‰¹å¾å€¼å¯¹åº”çš„ç‰¹å¾å‘é‡å¾€å¾€ä¸å™ªå£°æœ‰å…³ï¼Œå°†å®ƒä»¬èˆå¼ƒèƒ½åœ¨ä¸€å®šç¨‹åº¦ä¸Šèµ·åˆ°é™å™ªçš„æ•ˆæœï¼›\nè¿‡æ‹Ÿåˆï¼šPCA ä¿ç•™äº†ä¸»è¦ä¿¡æ¯ï¼Œä½†è¿™ä¸ªä¸»è¦ä¿¡æ¯åªæ˜¯é’ˆå¯¹è®­ç»ƒé›†çš„ï¼Œè€Œä¸”è¿™ä¸ªä¸»è¦ä¿¡æ¯æœªå¿…æ˜¯é‡è¦ä¿¡æ¯ã€‚æœ‰å¯èƒ½èˆå¼ƒäº†ä¸€äº›çœ‹ä¼¼æ— ç”¨çš„ä¿¡æ¯ï¼Œä½†æ˜¯è¿™äº›çœ‹ä¼¼æ— ç”¨çš„ä¿¡æ¯æ°å¥½æ˜¯é‡è¦ä¿¡æ¯ï¼Œåªæ˜¯åœ¨è®­ç»ƒé›†ä¸Šæ²¡æœ‰å¾ˆå¤§çš„è¡¨ç°ï¼Œæ‰€ä»¥ PCA ä¹Ÿå¯èƒ½åŠ å‰§äº†è¿‡æ‹Ÿåˆï¼›\nç‰¹å¾ç‹¬ç«‹ï¼šPCA ä¸ä»…å°†æ•°æ®å‹ç¼©åˆ°ä½ç»´ï¼Œå®ƒä¹Ÿä½¿å¾—é™ç»´ä¹‹åçš„æ•°æ®å„ç‰¹å¾ç›¸äº’ç‹¬ç«‹ï¼›\n\nç»†èŠ‚é›¶å‡å€¼åŒ–å½“å¯¹è®­ç»ƒé›†è¿›è¡Œ PCA é™ç»´æ—¶ï¼Œä¹Ÿéœ€è¦å¯¹éªŒè¯é›†ã€æµ‹è¯•é›†æ‰§è¡ŒåŒæ ·çš„é™ç»´ã€‚è€Œå¯¹éªŒè¯é›†ã€æµ‹è¯•é›†æ‰§è¡Œé›¶å‡å€¼åŒ–æ“ä½œæ—¶ï¼Œå‡å€¼å¿…é¡»ä»è®­ç»ƒé›†è®¡ç®—è€Œæ¥ï¼Œä¸èƒ½ä½¿ç”¨éªŒè¯é›†æˆ–è€…æµ‹è¯•é›†çš„ä¸­å¿ƒå‘é‡ã€‚\nå…¶åŸå› ä¹Ÿå¾ˆç®€å•ï¼Œå› ä¸ºæˆ‘ä»¬çš„è®­ç»ƒé›†æ—¶å¯è§‚æµ‹åˆ°çš„æ•°æ®ï¼Œæµ‹è¯•é›†ä¸å¯è§‚æµ‹æ‰€ä»¥ä¸ä¼šçŸ¥é“å…¶å‡å€¼ï¼Œè€ŒéªŒè¯é›†å†å¤§éƒ¨åˆ†æƒ…å†µä¸‹æ˜¯åœ¨å¤„ç†å®Œæ•°æ®åå†ä»è®­ç»ƒé›†ä¸­åˆ†ç¦»å‡ºæ¥ï¼Œä¸€èˆ¬ä¸ä¼šå•ç‹¬å¤„ç†ã€‚å¦‚æœçœŸçš„æ˜¯å•ç‹¬å¤„ç†äº†ï¼Œä¸èƒ½ç‹¬è‡ªæ±‚å‡å€¼çš„åŸå› æ˜¯å’Œæµ‹è¯•é›†ä¸€æ ·ã€‚\nå¦å¤–æˆ‘ä»¬ä¹Ÿéœ€è¦ä¿è¯ä¸€è‡´æ€§ï¼Œæˆ‘ä»¬æ‹¿è®­ç»ƒé›†è®­ç»ƒå‡ºæ¥çš„æ¨¡å‹ç”¨æ¥é¢„æµ‹æµ‹è¯•é›†çš„å‰æå‡è®¾å°±æ˜¯ä¸¤è€…æ˜¯ç‹¬ç«‹åŒåˆ†å¸ƒçš„ï¼Œå¦‚æœä¸èƒ½ä¿è¯ä¸€è‡´æ€§çš„è¯ï¼Œä¼šå‡ºç° Variance Shift çš„é—®é¢˜ã€‚\nå…¶ä»–é™ç»´æ–¹æ³•MDSå’Œæ ¸åŒ–çº¿æ€§é™ç»´ï¼Œæµå½¢å­¦ä¹ â€¦\nç”±äºPCAæ˜¯æœ€å¸¸ç”¨çš„é™ç»´ç®—æ³•ï¼Œåœ¨æ­¤å°±ä¸ä»‹ç»å…¶å®ƒäº†\n","categories":["æœºå™¨å­¦ä¹ ç®—æ³•"],"tags":["é™ç»´"]},{"title":"èšç±»ç®—æ³•","url":"/2021/08/07/%E8%81%9A%E7%B1%BB%E5%AD%A6%E4%B9%A0/","content":"èšç±»å‚è€ƒèµ„æ–™ï¼šã€Šæœºå™¨å­¦ä¹ ã€‹-å‘¨å¿—å\nåœ¨æ— ç›‘ç£å­¦ä¹ ä¸­ï¼Œè®­ç»ƒæ ·æœ¬çš„æ ‡è®°ä¿¡æ¯æ˜¯æœªçŸ¥çš„ï¼Œæ­¤ç±»å­¦ä¹ ä»»åŠ¡ä¸­ç ”ç©¶æœ€å¤šã€åº”ç”¨æœ€å¹¿çš„æ˜¯â€œèšç±»â€\nèšç±»è¯•å›¾å°†æ•°æ®é›†ä¸­çš„æ ·æœ¬åˆ’åˆ†ä¸ºè‹¥å¹²ä¸ªé€šå¸¸æ˜¯ä¸ç›¸äº¤çš„å­é›†ï¼Œæ¯ä¸ªå­é›†ç§°ä¸ºä¸€ä¸ªâ€œç°‡â€\nå½¢å¼åŒ–åœ°è¯´ï¼Œæ ·æœ¬é›†åŒ…å«mä¸ªæ— æ ‡è®°æ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬â€‹æ˜¯ä¸€ä¸ªnç»´ç‰¹å¾å‘é‡\nèšç±»ç®—æ³•ä¼šå°†æ ·æœ¬é›†Dåˆ’åˆ†ä¸ºkä¸ªä¸ç›¸äº¤çš„ç°‡ï¼Œå…¶ä¸­ç°‡äº’æ–¥ï¼Œä¸”æ‰€æœ‰ç°‡çš„å¹¶é›†ä¸ºæ•°æ®é›†D\nK-Meansç®—æ³•æ­¥éª¤\næ—è¾¹è¿˜æœ‰ä¸€ç¯‡å­—ï¼šä¸ºé¿å…è¿è¡Œæ—¶é—´è¿‡é•¿ï¼Œé€šå¸¸è®¾ç½®ä¸€ä¸ªæœ€å¤§è¿è¡Œè½®æ•°æˆ–æœ€å°è°ƒæ•´å¹…åº¦é˜ˆå€¼ï¼Œè‹¥è¾¾åˆ°æœ€å¤§è®ºè¿°æˆ–è°ƒæ•´å¹…åº¦å°äºé˜ˆå€¼ï¼Œåˆ™åœæ­¢è¿›è¡Œ\næˆ‘ä¸‹é¢çš„ä»£ç å®ç°ä¸ºé™åˆ¶è¿è¡Œæ¬¡æ•°ï¼Œsklearnä¹Ÿæ˜¯é™åˆ¶è¿­ä»£æ¬¡æ•°\nä»£ç å®ç°æ ¹æ®ä¸Šè¿°æµç¨‹å›¾ï¼Œç†Ÿæ‚‰æŒæ¡numpyå’Œpandasçš„å‡½æ•°ä½¿ç”¨ï¼Œæœ€åç”¨seabornè¿›è¡Œèšç±»æ•ˆæœå±•ç¤º\nåœ¨jupyter notebookä¸­åˆ†æ­¥è¿è¡Œ\nimport numpy as npimport pandas as pdimport seaborn as snsimport matplotlib.pyplot as pltfrom pandas import Seriesdf = pd.read_csv(\"points.txt\", sep=',', header=None)  # æˆ‘çš„ç‚¹é›†æ•°æ®ä¸ºpoints.txtï¼Œåˆ†éš”ç¬¦ä¸º,df.columns=['x', 'y']sns.scatterplot('x','y',data=df)  # ç»˜åˆ¶åŸå›¾æŸ¥çœ‹ç‚¹çš„åˆ†å¸ƒ\n\n\nä¸‹é¢ä¸ºæˆ‘ç¼–å†™çš„ä¸€ä¸ªçš„k_means\nclass k_means:    def __init__(self, X, k: int, max_iter=1000):        \"\"\"        X: æ•°æ®é›†ï¼Œarrayå½¢å¼        k: èšç±»ç°‡æ•°        \"\"\"        self.X = np.array(X)        self.k = k        self.max_iter = max_iter        ori_index = np.random.choice(a=list(range(len(X))), size=self.k, replace=False, p=None)        self.points = X[ori_index]  # å­˜æ”¾å‡å€¼å‘é‡    def cal_dist(self, x1, x2):        \"\"\"ç®—ä¸¤ç‚¹é—´çš„æ¬§æ°è·ç¦»\"\"\"        return np.sqrt(np.sum((x1 - x2) ** 2))    def classify(self):        \"\"\"        X: ç‚¹é›†ï¼Œæ¯ä¸€ä¸ªæ ·æœ¬æ˜¯nç»´å‘é‡        \"\"\"        X = self.X        point_marks = dict()        for j in range(len(X)):            dist = []            for i in range(self.k):                # ç®—å‡ºæ ·æœ¬x_jä¸å„å‡å€¼å‘é‡çš„è·ç¦»                dist.append(self.cal_dist(X[j], self.points[i]))            mark = dist.index(min(dist))  # é€‰å–è·ç¦»æœ€è¿‘çš„é‚£ä¸ªç±»ä½œä¸ºæ ‡è®°            point_marks.setdefault(j, mark)  # å»ºç«‹èµ·è”ç³»ï¼Œç¬¬jä¸ªç‚¹æ˜¯ç¬¬markç±»        mark_record = Series(point_marks.values())  # è®°å½•ç€æ¯ä¸ªç‚¹çš„ç±»æ ‡è®°        # è®¡ç®—æ–°å‡å€¼å‘é‡å¹¶æ›´æ–°        for i in range(self.k):            tem_points = X[mark_record[mark_record == i].index]  # è·å–ç¬¬iç±»æ ·æœ¬ç‚¹çš„æ•°æ®            point_num, fea_num = tem_points.shape            for p in range(fea_num):                self.points[i][p] = tem_points[:, p].sum() / point_num        return mark_record    def fit(self):        \"\"\"ä¸æ–­è¿›è¡Œè¿­ä»£ï¼Œæœ€ç»ˆè·å¾—ä¸€ä¸ªè®°å½•åˆ’åˆ†çš„serieså¯¹è±¡\"\"\"        _series = None        for i in range(self.max_iter):            _dict = self.classify()        return _series\n\ndata = np.array(df)model = k_means(data, k=5, max_iter=500)record = model.fit()record.name = \"class\"new_df = pd.concat([df, record], axis=1)sns.scatterplot('x','y',data=new_df, hue=\"class\", palette=\"Set2\")\n\n\n\nk=5æ—¶çš„èšç±»æ•ˆæœå›¾\n\nåŒæ—¶ï¼Œæˆ‘ä¹Ÿä½¿ç”¨äº†sklearnçš„KMeansèšç±»æ–¹æ³•è¿›è¡Œæ•ˆæœä¸Šçš„å¯¹æ¯”\nfrom sklearn.cluster import KMeansskmodel = KMeans(n_clusters=5, random_state=0,).fit(data)sk_label = Series(skmodel.labels_)sk_label.name = \"class\"sk_df = pd.concat([df, sk_label], axis=1)sns.scatterplot('x','y',data=sk_df, hue=\"class\", palette=\"Set2\")\n\n\næ•ˆæœè¿˜æ²¡æˆ‘çš„å¥½\né«˜æ–¯æ··åˆèšç±»é¦–å…ˆè¦æ˜ç™½ä»€ä¹ˆæ˜¯ï¼ˆå¤šå…ƒï¼‰é«˜æ–¯åˆ†å¸ƒã€‚\nå¯¹nç»´æ ·æœ¬ç©ºé—´Xä¸­çš„å‘é‡ï¼Œè‹¥æœä»é«˜æ–¯åˆ†å¸ƒï¼Œå…¶æ¦‚ç‡å¯†åº¦å‡½æ•°ä¸ºå…¶ä¸­ï¼Œä¸ºnç»´å‡å€¼å‘é‡ï¼Œä¸ºçš„åæ–¹å·®çŸ©é˜µã€‚\nç”±ä¸Šå¼å¯çœ‹å‡ºé«˜æ–¯åˆ†å¸ƒå®Œå…¨ç”±å‡å€¼å‘é‡å’Œåæ–¹å·®çŸ©é˜µâ€‹è¿™ä¸¤ä¸ªå‚æ•°ç¡®å®šï¼Œä¸ºäº†æ˜ç¡®å…¶ä¸ç›¸åº”å‚æ•°çš„ä¾èµ–å…³ç³»ï¼Œæˆ‘ä»¬å°†æ¦‚ç‡å¯†åº¦å‡½æ•°è®°ä¸º\næˆ‘ä»¬å¯å®šä¹‰é«˜æ–¯æ··åˆåˆ†å¸ƒè¯¥åˆ†å¸ƒå…±ç”±kä¸ªæ··åˆæˆåˆ†ç»„æˆï¼Œæ¯ä¸ªæ··åˆæˆåˆ†å¯¹åº”ä¸€ä¸ªé«˜æ–¯åˆ†å¸ƒã€‚å…¶ä¸­ä¸ºç¬¬iä¸ªé«˜æ–¯æ··åˆæˆä»½çš„å‚æ•°ï¼Œè€Œä¸ºç›¸åº”çš„æ··åˆç³»æ•°\nç®—æ³•æ­¥éª¤\nå¯†åº¦èšç±»é¡¾åæ€ä¹‰ï¼ŒåŸºäºå¯†åº¦çš„èšç±»ï¼Œä»æ ·æœ¬å¯†åº¦çš„è§’åº¦æ¥è€ƒå¯Ÿæ ·æœ¬ä¹‹é—´çš„å¯è¿æ¥æ€§ï¼Œå¹¶ç»™äºˆå¯è¿æ¥æ ·æœ¬ä¸æ–­æ‰©å±•èšç±»ç°‡ä»¥è·å¾—æœ€ç»ˆçš„èšç±»ç»“æœã€‚\nè‘—åç®—æ³•æœ‰DBSCANï¼Œå®ƒåŸºäºä¸€ç»„â€œé¢†åŸŸâ€å‚æ•°æ¥åˆ»ç”»æ ·æœ¬åˆ†å¸ƒçš„ç´§å¯†ç¨‹åº¦\nç»™å®šæ•°æ®é›†ï¼Œå®šä¹‰ä¸‹é¢è¿™å‡ ä¸ªæ¦‚å¿µï¼š\n\nâ€‹é‚»åŸŸï¼šå¯¹ï¼Œå…¶é‚»åŸŸåŒ…å«æ ·æœ¬é›†Dä¸­ä¸çš„è·ç¦»ä¸å¤§äºçš„æ ·æœ¬ï¼Œå³\n\næ ¸å¿ƒå¯¹è±¡ï¼šè‹¥çš„é‚»åŸŸè‡³å°‘åŒ…å«ä¸ªæ ·æœ¬ï¼Œå³ï¼Œåˆ™ä¸ºä¸€ä¸ªæ ¸å¿ƒå¯¹è±¡\n\nå¯†åº¦ç›´è¾¾ï¼šè‹¥ä½äºçš„é‚»åŸŸä¸­ï¼Œä¸”ä¸ºæ ¸å¿ƒå¯¹è±¡ï¼Œåˆ™ç§°ç”±å¯†åº¦ç›´è¾¾\n\nå¯†åº¦å¯è¾¾ï¼šå¯¹â€‹å’Œ â€‹ï¼Œè‹¥å­˜åœ¨æ ·æœ¬åºåˆ—ï¼Œå…¶ä¸­ä¸”ç”±å¯†åº¦ç›´è¾¾ï¼Œåˆ™ç§°ç”±å¯†åº¦å¯è¾¾â€‹\n\nå¯†åº¦ç›¸è¿ï¼šå¯¹â€‹å’Œ â€‹ï¼Œè‹¥å­˜åœ¨â€‹ä½¿å¾—â€‹ä¸â€‹å‡æœ‰â€‹å¯†åº¦å¯è¾¾ï¼Œåˆ™ç§°ç”±ä¸â€‹å¯†åº¦é¡¹é“¾\n\n\n\nåŸºäºè¿™äº›å®šä¹‰ï¼ŒDBSCANå°†â€œç°‡â€å®šä¹‰ä¸ºï¼šç”±å¯†åº¦å¯è¾¾å…³ç³»å¯¼å‡ºçš„æœ€å¤§çš„å¯†åº¦ç›¸è¿æ ·æœ¬é›†åˆã€‚\nç»™å®šé‚»åŸŸå‚æ•°ï¼Œç°‡æ˜¯æ»¡è¶³ä»¥ä¸‹æ€§è´¨çš„éç©ºæ ·æœ¬å­é›†ï¼š\nè¿æ¥æ€§ï¼šä¸å¯†åº¦ç›¸è¿\næœ€å¤§æ€§ï¼šç”±å¯†åº¦å¯è¾¾\nç®—æ³•æ­¥éª¤\nä»£ç å®ç°æˆ‘è‡ªå·±å†™çš„é‚£ä¸ªæ€»æ˜¯ä¼šåœ¨æ­¥éª¤16å‡ºé—®é¢˜ï¼Œæˆ‘æŸ¥äº†ä¸‹ç½‘ä¸Šçš„èµ„æ–™ï¼Œä¹Ÿåªæ˜¯è§‰å¾—è·Ÿä»–é‡‡ç”¨çš„æ•°æ®ç»“æ„ä¸å¤ªä¸€æ ·ï¼Œæˆ‘ç”¨çš„å­—å…¸ï¼Œä»–ç”¨çš„åˆ—è¡¨ï¼Œå°±æ˜¯ä¸çŸ¥é“ä¸ºå•¥æˆ‘ï¼çš„ï¼ä¸ï¼è¡Œï¼å¯ï¼æ¶ï¼\n\nå‚è€ƒèµ„æ–™ï¼š\næœ€åæ•´ä½“çš„ä»£ç æ˜¯è¿™æ ·çš„\nimport randomimport copyimport numpy as npclass DBSCAN:    def __init__(self, eps=0.5, min_samples=5):        self.eps = eps        self.min_samples = min_samples    def fit(self, X):        m, n = X.shape        k = 0  # èšç±»ç°‡æ•°        neighbor_list = []        gama = set([x for x in range(len(X))])  # åˆå§‹æ—¶å°†æ‰€æœ‰ç‚¹æ ‡è®°ä¸ºæœªè®¿é—®        labels = [-1 for _ in range(len(X))]  # åˆå§‹åŒ–æ¯ä¸ªç‚¹çš„ç±»æ ‡ç­¾ä¸º-1        def find_neighbor(j):            \"\"\"æ‰¾åˆ°jçš„é‚»å±…ï¼Œè¿”å›é›†åˆ\"\"\"            eps_domain = list()            for i in range(m):                dist = self.cal_dist(X[j], X[i])                if dist &lt;= self.eps:                    eps_domain.append(i)            return set(eps_domain)        def find_object():            \"\"\"æ‰¾åˆ°æ ¸å¿ƒå¯¹è±¡é›†åˆ\"\"\"            omega_list = []            for i in range(m):                neighbor = find_neighbor(i)                neighbor_list.append(neighbor)                if len(neighbor) &gt;= self.min_samples:                    omega_list.append(i)            return set(omega_list)        core_obj = find_object()        while len(core_obj) &gt; 0:            gama_old = copy.deepcopy(gama)            j = random.choice(list(core_obj))  # éšæœºé€‰å–ä¸€ä¸ªæ ¸å¿ƒå¯¹è±¡            k = k + 1            Q = list()            Q.append(j)            gama.remove(j)            while len(Q) &gt; 0:                q = Q[0]                Q.remove(q)                if len(neighbor_list[q]) &gt;= self.min_samples:                    delta = neighbor_list[q] &amp; gama                    deltalist = list(delta)                    for i in range(len(delta)):                        Q.append(deltalist[i])                        gama = gama - delta            Ck = gama_old - gama            Cklist = list(Ck)            for i in range(len(Ck)):                labels[Cklist[i]] = k            core_obj = core_obj - Ck        return labels    def cal_dist(self, x1, x2):        \"\"\"ç®—ä¸¤ç‚¹é—´çš„æ¬§æ°è·ç¦»\"\"\"        return np.sqrt(np.sum((x1 - x2) ** 2))\n\n\n\nè¿›è¡Œç»˜å›¾\nmodel = DBSCAN(eps=2, min_samples=15)df = pd.read_csv(\"points.txt\", sep=',', header=None)df.columns = ['x', 'y']data = np.array(df)labels = model.fit(data)record = Series(labels)record.name = \"class\"new_df = pd.concat([df, record], axis=1)sns.scatterplot('x', 'y', data=new_df, hue=\"class\", palette=\"Set2\")\n\næ•ˆæœå¦‚ä¸‹å›¾ï¼š\n\næˆ‘è§‰å¾—è¿™ä¸ªæ˜¯æˆ‘ç”¨çš„æ•°æ®é›†ä¸­åˆ†ç±»æ•ˆæœæœ€å¥½çš„ä¸€ä¸ªç®—æ³•ï¼Œä¸è¿‡å€¼å¾—æ³¨æ„çš„æ˜¯åˆ†ç±»çš„æ•ˆæœéå¸¸ä¾èµ–äºepsilonå’Œmin_samplesä¸¤ä¸ªå‚æ•°å€¼ï¼Œæˆ‘è°ƒäº†ä¸ƒæ¬¡æ‰è°ƒå‡ºè¿™ç§æ•ˆæœã€‚\nç›¸å¯¹æ¥è¯´ï¼Œèšç±»çš„ç®—æ³•æ¯”ä¹‹å‰å­¦ä¹ çš„ç®—æ³•å¥½å®ç°å¾ˆå¤šï¼Œåˆå¤ä¹ äº†è®¸å¤špythonçš„è¯­æ³•çŸ¥è¯†ï¼Œä¸æˆ³ï¼ç»“æŸèšç±»éƒ¨åˆ†çš„å­¦ä¹ \n","categories":["æœºå™¨å­¦ä¹ ç®—æ³•"],"tags":["èšç±»"]}]