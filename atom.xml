<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Horaceの云端梦境</title>
  
  
  <link href="https://horacehht.github.io/atom.xml" rel="self"/>
  
  <link href="https://horacehht.github.io/"/>
  <updated>2021-05-29T15:58:38.109Z</updated>
  <id>https://horacehht.github.io/</id>
  
  <author>
    <name>Horace</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>设置代理爬取豆瓣书籍</title>
    <link href="https://horacehht.github.io/2021/05/29/%E8%AE%BE%E7%BD%AE%E4%BB%A3%E7%90%86%E7%88%AC%E5%8F%96%E8%B1%86%E7%93%A3%E4%B9%A6%E7%B1%8D/"/>
    <id>https://horacehht.github.io/2021/05/29/%E8%AE%BE%E7%BD%AE%E4%BB%A3%E7%90%86%E7%88%AC%E5%8F%96%E8%B1%86%E7%93%A3%E4%B9%A6%E7%B1%8D/</id>
    <published>2021-05-29T15:57:06.000Z</published>
    <updated>2021-05-29T15:58:38.109Z</updated>
    
    <content type="html"><![CDATA[<h1 id="设置代理爬取豆瓣书籍"><a href="#设置代理爬取豆瓣书籍" class="headerlink" title="设置代理爬取豆瓣书籍"></a>设置代理爬取豆瓣书籍</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>爬取网页大都可分为三个步骤：</p><ol><li>访问网页：一般使用requests库，不嫌麻烦的话可以使用python内置的urllib库</li><li>解析网页：使用Xpath，BeautifulSoup，正则表达式等方式进行网页信息的提取</li><li>存储数据：①存入IO流文件，如txt，csv等文件    ②存入数据库，主流的有MySQL，mongodb</li></ol><p>本文开发环境为python3.8，爬取的数据存入MySQL数据库中</p><h2 id="访问网页"><a href="#访问网页" class="headerlink" title="访问网页"></a>访问网页</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">url = <span class="string">&#x27;目标网址&#x27;</span></span><br><span class="line">res = requests.get(url)</span><br></pre></td></tr></table></figure><p>这样即可完成一次网页的访问。但一般都要加上请求头，称为headers。一般的网站请求的headers中加入<code>User-Agent</code>项参数即可。</p><p>如果你用的是谷歌浏览器，可在网页栏输入<code>chrome::version</code>查看自己的<code>User-Agent</code>项，叫“用户代理”</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://horacehhtbucket.oss-cn-guangzhou.aliyuncs.com/img/image-20210521100544782.png"                      alt="image-20210521100544782"                ></p><p>如果不是，也可以按F12，Ctrl+R，随便点进一个请求，<code>Requests Headers</code>项中的<code>User-Agent</code>就是你的User-Agent。</p><p>于是代码应该改成这样</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;填入你的user-agent&#x27;</span></span><br><span class="line">    ...根据不同的网站加入不同的参数</span><br><span class="line">&#125;</span><br><span class="line">res = requests.get(url, headers=headers)</span><br></pre></td></tr></table></figure><p>不加的话，你的请求中User-Agent的值则是python爬虫，网站就会拒绝访问，这样你就无法得到网站返回的数据。</p><h3 id="设置代理"><a href="#设置代理" class="headerlink" title="设置代理"></a>设置代理</h3><h4 id="为什么要设置代理？"><a href="#为什么要设置代理？" class="headerlink" title="为什么要设置代理？"></a>为什么要设置代理？</h4><p>背景：本人要在某次考核任务最后一天中爬取数据量超过3k5的数据，时间紧，数据量说小不小，说大不大。如果采用平常的爬虫方法，每一次time.sleep几秒，这样久了，豆瓣自然会发现，然后把ip给封了，这样就没办法爬了，考核任务就泡汤了…</p><p>题外话：time.sleep()设置的秒数最好是<strong>随机数</strong>，如果是固定的秒数，久而久之也很容易被封ip。</p><p>所以，<strong>设置代理</strong>这种切换ip的方式就很适合<strong>短时间爬取大量数据</strong></p><p>代理有多种</p><p>①自己去爬取免费的代理，建立自己的代理池，难度大，技术要求高，且大多免费代理都是用不了的。</p><p>②使用付费代理</p><p>本文中使用的是付费代理，叫多贝云代理，购买了http隧道代理中的套餐3，套餐的特点是：<strong>每个请求随机分配IP</strong></p><p>注：购买时需要实名认证</p><h4 id="获取分配的ip"><a href="#获取分配的ip" class="headerlink" title="获取分配的ip"></a>获取分配的ip</h4><p>注：不同的付费代理不同的套餐<strong>获取ip的方式不同</strong>，根据官方指示即可</p><p>购买后，多贝云会分配一个账号，密码和服务器地址给你</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://horacehhtbucket.oss-cn-guangzhou.aliyuncs.com/img/image-20210521214659733.png"                      alt="image-20210521214659733"                ></p><p>根据他的指引构造代理参数即可</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://horacehhtbucket.oss-cn-guangzhou.aliyuncs.com/img/image-20210521214853713.png"                      alt="image-20210521214853713"                ></p><p>于是我们向服务器地址端口请求，服务器即可返回一个可用的ip来伪装我们的ip</p><h3 id="访问网页函数"><a href="#访问网页函数" class="headerlink" title="访问网页函数"></a>访问网页函数</h3><p>于是我们定义一个访问网页的函数，返回响应。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">visit</span>(<span class="params">targetUrl</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;访问网址，返回响应&quot;&quot;&quot;</span></span><br><span class="line">    session = requests.Session()</span><br><span class="line">    session.keep_alive = <span class="literal">False</span></span><br><span class="line">    res = session.get(targetUrl, proxies=proxies, headers=random.choice(headers))</span><br><span class="line">    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><p>这里我还用了随机UA，就是找了不同的user-agent，每次访问从中随机选取一个ua。</p><p>这里的headers是个列表</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://horacehhtbucket.oss-cn-guangzhou.aliyuncs.com/img/image-20210521233503065.png"                      alt="image-20210521233503065"                ></p><h2 id="解析网页"><a href="#解析网页" class="headerlink" title="解析网页"></a>解析网页</h2><p>按F12或右键检查进入“开发者选项”，利用图片中红框的功能可以迅速定位所提取信息的节点位置</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://horacehhtbucket.oss-cn-guangzhou.aliyuncs.com/img/image-20210521215919135.png"                      alt="image-20210521215919135"                ></p><p>此处运用XPth和BeautifulSoup进行网页的解析，并将解析方法编写成类。</p><p>注：建议对自己的解析方法多对几本书进行尝试，因为不同网页排版可能不同噢~</p><p>爬取的字段为book_name（书名），author（作者），press（出版社），publishing_year（出版年份），page_num（页数），price（定价），ISBN，score（评分），rating_num（评分人数），content_introduction（内容简介），cover_url（封面图片网页链接），readers（读者的个人主页链接）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 库导入部分</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CrawlBook</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, res</span>):</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            self.soup = BeautifulSoup(res.text, <span class="string">&#x27;lxml&#x27;</span>)  <span class="comment"># 初始化</span></span><br><span class="line">            self.html = etree.HTML(res.text)  <span class="comment"># 初始化</span></span><br><span class="line">            self.data = <span class="built_in">dict</span>()  <span class="comment"># 生成一个空字典</span></span><br><span class="line">            self.get_book_name()</span><br><span class="line">            self.get_author()</span><br><span class="line">            self.get_many()</span><br><span class="line">            self.get_score()</span><br><span class="line">            self.get_rating_num()</span><br><span class="line">            self.get_content()</span><br><span class="line">            self.get_image()</span><br><span class="line">            self.get_readers()</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            self.data.setdefault(<span class="string">&#x27;author&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">            self.data.setdefault(<span class="string">&#x27;出版社:&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">            self.data.setdefault(<span class="string">&#x27;出版年:&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">            self.data.setdefault(<span class="string">&#x27;页数:&#x27;</span>, <span class="string">&#x27;0&#x27;</span>)</span><br><span class="line">            self.data.setdefault(<span class="string">&#x27;定价:&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">            self.data.setdefault(<span class="string">&#x27;ISBN:&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">            self.data.setdefault(<span class="string">&#x27;score&#x27;</span>, <span class="number">0.0</span>)</span><br><span class="line">            self.data.setdefault(<span class="string">&#x27;rating_num&#x27;</span>, <span class="number">0</span>)</span><br><span class="line">            self.data.setdefault(<span class="string">&#x27;content_introduction&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">            self.data.setdefault(<span class="string">&#x27;readers&#x27;</span>, <span class="string">&#x27;[]&#x27;</span>)</span><br><span class="line">            <span class="built_in">print</span>(e)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_book_name</span>(<span class="params">self</span>):</span></span><br><span class="line">        book_name = self.soup.find(name=<span class="string">&#x27;span&#x27;</span>, attrs=&#123;<span class="string">&#x27;property&#x27;</span>: <span class="string">&#x27;v:itemreviewed&#x27;</span>&#125;).string</span><br><span class="line">        <span class="comment"># 找到节点名为span，属性property值为itemreviewd的节点，.string获取其文本内容</span></span><br><span class="line">        self.data.setdefault(<span class="string">&#x27;book_name&#x27;</span>, book_name)  <span class="comment"># 将其添加到字典中，下面的解析方法大同小异</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_author</span>(<span class="params">self</span>):</span></span><br><span class="line">        author = self.soup.find(name=<span class="string">&#x27;span&#x27;</span>, text=re.<span class="built_in">compile</span>(<span class="string">&#x27;.*?作者.*?&#x27;</span>)).next_sibling.next_sibling\</span><br><span class="line">            .string.replace(<span class="string">&#x27;\n&#x27;</span>, <span class="string">&#x27;&#x27;</span>).replace(<span class="string">&#x27; &#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">        self.data.setdefault(<span class="string">&#x27;author&#x27;</span>, author)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_many</span>(<span class="params">self</span>):</span></span><br><span class="line">        want_to_spider = [<span class="string">&#x27;出版社:&#x27;</span>, <span class="string">&#x27;出版年:&#x27;</span>, <span class="string">&#x27;页数:&#x27;</span>, <span class="string">&#x27;定价:&#x27;</span>, <span class="string">&#x27;ISBN:&#x27;</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> self.soup.find_all(name=<span class="string">&#x27;span&#x27;</span>, attrs=&#123;<span class="string">&#x27;class&#x27;</span>: <span class="string">&#x27;pl&#x27;</span>&#125;):</span><br><span class="line">            <span class="keyword">if</span> i.string <span class="keyword">in</span> want_to_spider:</span><br><span class="line">                self.data.setdefault(i.string, i.next_sibling.replace(<span class="string">&#x27; &#x27;</span>, <span class="string">&#x27;&#x27;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_score</span>(<span class="params">self</span>):</span></span><br><span class="line">        score = <span class="built_in">float</span>(self.soup.find(name=<span class="string">&#x27;strong&#x27;</span>, attrs=&#123;<span class="string">&#x27;property&#x27;</span>: <span class="string">&#x27;v:average&#x27;</span>&#125;).string)</span><br><span class="line">        self.data.setdefault(<span class="string">&#x27;score&#x27;</span>, score)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_rating_num</span>(<span class="params">self</span>):</span></span><br><span class="line">        rating_num = <span class="built_in">int</span>(self.soup.find(name=<span class="string">&#x27;span&#x27;</span>, attrs=&#123;<span class="string">&#x27;property&#x27;</span>: <span class="string">&#x27;v:votes&#x27;</span>&#125;).string)</span><br><span class="line">        self.data.setdefault(<span class="string">&#x27;rating_num&#x27;</span>, rating_num)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_content</span>(<span class="params">self</span>):</span></span><br><span class="line">        l = <span class="string">&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> self.soup.find(name=<span class="string">&#x27;div&#x27;</span>, attrs=&#123;<span class="string">&#x27;class&#x27;</span>: <span class="string">&#x27;intro&#x27;</span>&#125;).contents:</span><br><span class="line">                l += <span class="built_in">str</span>(i)</span><br><span class="line">            self.data.setdefault(<span class="string">&#x27;content_introduction&#x27;</span>, l.strip())</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(e)</span><br><span class="line">            self.data.setdefault(<span class="string">&#x27;content_introduction&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_image</span>(<span class="params">self</span>):</span></span><br><span class="line">        image_url = self.soup.find(name=<span class="string">&#x27;img&#x27;</span>, attrs=&#123;<span class="string">&#x27;rel&#x27;</span>: <span class="string">&#x27;v:photo&#x27;</span>&#125;)[<span class="string">&#x27;src&#x27;</span>]  <span class="comment"># 获取节点的src属性值</span></span><br><span class="line">        self.data.setdefault(<span class="string">&#x27;cover_url&#x27;</span>, image_url)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_readers</span>(<span class="params">self</span>):</span></span><br><span class="line">        readers = <span class="built_in">str</span>(self.html.xpath(<span class="string">&#x27;//*[@id=&quot;collector&quot;]//div/div[2]/a/@href&#x27;</span>))  </span><br><span class="line">        <span class="comment"># 这里用的是xpath的解析方法，获取所有属性值为collector下的所有div节点下的第二个div节点的a节点的href属性值</span></span><br><span class="line">        self.data.setdefault(<span class="string">&#x27;readers&#x27;</span>, readers)</span><br></pre></td></tr></table></figure><p>注：字典的setdefault函数是添加键值对的一种方式，<strong>如果已有这个键则不添加</strong>，没有则添加。</p><p>这可以窥探出我为什么<strong>在try-except语句的except中加上相应字段的setdefault</strong>。因为豆瓣的书籍间网页排布是不同的，它就是比较特殊，有些书没有ISBN，有些书没有评分和评论人数…所以以固定的方式去提取这些字段，必会报错，所以遇到这种报错时，进到except语句为数据赋上一些方便处理的空值。<del>虽说我也不知道为什么之后还是有空值</del></p><p>小插入一句，<strong>异常处理真的很重要！！！</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    一些可能会出错的语句</span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(e)  <span class="comment"># 这个print(e)可以让我们看到出错的原因，</span></span><br><span class="line">    <span class="keyword">pass</span>  <span class="comment"># 这里的pass你可以填入你异常处理的语句</span></span><br></pre></td></tr></table></figure><p><strong>这样子所有的字段数据都存入了data中</strong>，之后我们实例化一个对象，对象.data即可查看我们爬取的数据啦。</p><p>我们以《追风筝的人》为例：</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://horacehhtbucket.oss-cn-guangzhou.aliyuncs.com/img/image-20210521223724610.png"                      alt="image-20210521223724610"                ></p><h2 id="存储数据"><a href="#存储数据" class="headerlink" title="存储数据"></a>存储数据</h2><p>使用MySQL数据库进行数据的存储</p><h3 id="建表"><a href="#建表" class="headerlink" title="建表"></a>建表</h3><p>要<strong>根据爬取的字段建立相应的表</strong>（如果是新用户还要新建连接，这里就不多赘述了）</p><p>可以用python建表，也可以用navicat（MySQL的一个可视化工具）建表。</p><p>这里用python建表</p><p>python通过第三方库<strong>pymysql</strong>与MySQL与数据库进行交互，对数据进行增删查改。</p><p>首先要<code>import pymysql</code>，没有安装库的就去安装。</p><p>直接贴代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"></span><br><span class="line">conn = pymysql.connect(  <span class="comment"># 连接本地数据库</span></span><br><span class="line">    host=<span class="string">&quot;localhost&quot;</span>,</span><br><span class="line">    user=<span class="string">&quot;root&quot;</span>,  <span class="comment"># 要填root</span></span><br><span class="line">    password=<span class="string">&quot;htht0928&quot;</span>,  <span class="comment"># 填上自己的密码</span></span><br><span class="line">    database=<span class="string">&quot;doubanbook&quot;</span>,  <span class="comment"># 数据库名</span></span><br><span class="line">    charset=<span class="string">&quot;utf8&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">cur = conn.cursor()  <span class="comment"># 获得光标</span></span><br><span class="line">create_books_table_sql = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">     CREATE TABLE `books`(</span></span><br><span class="line"><span class="string">    `book_name` VARCHAR(20) NOT NULL UNIQUE,</span></span><br><span class="line"><span class="string">    `author` VARCHAR(20) NOT NULL,</span></span><br><span class="line"><span class="string">    `press` VARCHAR(20),</span></span><br><span class="line"><span class="string">    `publishing_year` VARCHAR(10),</span></span><br><span class="line"><span class="string">    `score` FLOAT,</span></span><br><span class="line"><span class="string">    `rating_num` INTEGER,</span></span><br><span class="line"><span class="string">    `page_num` VARCHAR(10),</span></span><br><span class="line"><span class="string">    `price` VARCHAR(10),</span></span><br><span class="line"><span class="string">    `ISBN` VARCHAR(30),</span></span><br><span class="line"><span class="string">    `content_introduction` VARCHAR(2000),</span></span><br><span class="line"><span class="string">    `cover_url` VARCHAR(100),</span></span><br><span class="line"><span class="string">    `readers` VARCHAR (400)</span></span><br><span class="line"><span class="string">    )</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span>  <span class="comment"># sql语句</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    cur.execute(create_books_table_sql)  <span class="comment"># 执行sql语句</span></span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(e)</span><br><span class="line">    conn.rollback()  <span class="comment"># 发生错误则回滚</span></span><br></pre></td></tr></table></figure><p>运行后即可建立相应的表。</p><h3 id="插入数据"><a href="#插入数据" class="headerlink" title="插入数据"></a>插入数据</h3><p>编写save_to_mysql函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_to_mysql</span>(<span class="params">data</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;data是书籍的信息，json格式，要插入到books这个表&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    book_name = data.get(<span class="string">&#x27;book_name&#x27;</span>)</span><br><span class="line">    author = data.get(<span class="string">&#x27;author&#x27;</span>)</span><br><span class="line">    press = data.get(<span class="string">&#x27;出版社:&#x27;</span>)</span><br><span class="line">    publishing_year = data.get(<span class="string">&#x27;出版年:&#x27;</span>)</span><br><span class="line">    page_num = data.get(<span class="string">&#x27;页数:&#x27;</span>)</span><br><span class="line">    price = data.get(<span class="string">&#x27;定价:&#x27;</span>)</span><br><span class="line">    ISBN = data.get(<span class="string">&#x27;ISBN:&#x27;</span>)</span><br><span class="line">    score = data.get(<span class="string">&#x27;score&#x27;</span>)</span><br><span class="line">    rating_num = data.get(<span class="string">&#x27;rating_num&#x27;</span>)</span><br><span class="line">    content_introduction = data.get(<span class="string">&#x27;content_introduction&#x27;</span>)</span><br><span class="line">    cover_url = data.get(<span class="string">&#x27;cover_url&#x27;</span>)</span><br><span class="line">    readers = data.get(<span class="string">&#x27;readers&#x27;</span>)</span><br><span class="line">    insert_data = (book_name, author, press, publishing_year, score, rating_num, page_num, price, ISBN,</span><br><span class="line">                   content_introduction, cover_url, readers)</span><br><span class="line">    insert_sql = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        INSERT INTO books(book_name, author, press, publishing_year, score, rating_num, page_num, price,</span></span><br><span class="line"><span class="string">        ISBN, content_introduction, cover_url, readers)</span></span><br><span class="line"><span class="string">        VALUES(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span>  <span class="comment"># 向字段中增添相应的数据</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># 执行sql语句</span></span><br><span class="line">        cur.execute(insert_sql, insert_data)</span><br><span class="line">        <span class="comment"># 提交执行</span></span><br><span class="line">        conn.commit()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;《&#x27;</span> + book_name + <span class="string">&#x27;》&#x27;</span> + <span class="string">&#x27;信息已存储成功!&#x27;</span>)  <span class="comment"># 方便我们看到爬取的过程</span></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(e)</span><br><span class="line">        conn.rollback()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;存储失败!&#x27;</span>)</span><br></pre></td></tr></table></figure><p>注：提取字典数据时没用dict[‘key’]的方法获取的原因是如果没有这个字段，会直接报错，整个程序直接停下来。</p><p>如果用.get，即是没有这个字段，get这个字段会返回None，而不是报错。</p><p>在爬取过程中，我遇到了爬取成功但是却发现数据并没有存入数据库中的情况，查阅资料后发现是<code>mysql锁住了</code>，进入win系统<strong>重启MySQL服务</strong>即可。</p><h2 id="进行爬取"><a href="#进行爬取" class="headerlink" title="进行爬取"></a>进行爬取</h2><h3 id="流程介绍"><a href="#流程介绍" class="headerlink" title="流程介绍"></a>流程介绍</h3><p>爬取的整个过程：进入每个标签页，获取该页的20本书的url，再进入每本书的url进行信息的提取</p><p>提取标签</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://horacehhtbucket.oss-cn-guangzhou.aliyuncs.com/img/image-20210521230109014.png"                      alt="image-20210521230109014"                ></p><p>进入标签页提取这页中20本书的url</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://horacehhtbucket.oss-cn-guangzhou.aliyuncs.com/img/image-20210521230224249.png"                      alt="image-20210521230224249"                ></p><p>随后就是进入书籍页面爬取数据。</p><h3 id="编写相关函数"><a href="#编写相关函数" class="headerlink" title="编写相关函数"></a>编写相关函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">crawl_tags</span>(<span class="params">page</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;获取每个标签网页的第page页&quot;&quot;&quot;</span></span><br><span class="line">    url = <span class="string">&#x27;https://book.douban.com/tag/?view=type&amp;icn=index-sorttags-all&#x27;</span></span><br><span class="line">    res = visit(url)</span><br><span class="line">    html = etree.HTML(res.text)</span><br><span class="line">    tags = html.xpath(<span class="string">&#x27;//*[@id=&quot;content&quot;]//tr/td/a/text()&#x27;</span>)</span><br><span class="line">    pages_url = [<span class="string">&#x27;https://book.douban.com/tag/&#x27;</span> + tag + <span class="string">&#x27;?=&#x27;</span> + <span class="built_in">str</span>((page-<span class="number">1</span>)*<span class="number">20</span>) + <span class="string">&#x27;&amp;type=T&#x27;</span> <span class="keyword">for</span> tag <span class="keyword">in</span> tags]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;已获取&#x27;</span> + <span class="built_in">str</span>(<span class="built_in">len</span>(pages_url)) + <span class="string">&#x27;个标签网页&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> pages_url</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_book_urls</span>(<span class="params">tag_url</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;获取每个标签网页中的第一页，20本书&quot;&quot;&quot;</span></span><br><span class="line">    l = <span class="built_in">set</span>()</span><br><span class="line">    i = <span class="number">20</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        res = visit(tag_url)</span><br><span class="line">        html = etree.HTML(res.text)</span><br><span class="line">        books_urls = html.xpath(<span class="string">&#x27;//*[@id=&quot;subject_list&quot;]/ul//li/div[2]/h2/a/@href&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> book_url <span class="keyword">in</span> books_urls:</span><br><span class="line">            l.add(book_url)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;已获取%d本书&#x27;</span> % i)</span><br><span class="line">        i += <span class="number">20</span></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(e)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;要停一会!休息2秒&#x27;</span>)  <span class="comment"># 因为爬了一定数据量后，代理会跳出proxyerror错误，停一会即可</span></span><br><span class="line">        time.sleep(<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">list</span>(l)</span><br></pre></td></tr></table></figure><p>之前没try-except语句总是爬一会就停，郁闷死我了。这种写法是我顿悟出来的，这样写之后，真的是<strong>飞快地爬</strong>。</p><p>下面还会用到这样的写法</p><p><strong>主函数</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    tags_url = crawl_tags(<span class="number">1</span>)  <span class="comment"># 获取每个标签页的第一页</span></span><br><span class="line">    <span class="comment"># 我们可以通过对crawl_tags传入不同的页数，获取每个标签页的第n页</span></span><br><span class="line">    <span class="keyword">for</span> page <span class="keyword">in</span> tags_url:</span><br><span class="line">        book_urls = get_book_urls(page)  <span class="comment"># 某个标签的第一页的书链接</span></span><br><span class="line">        <span class="keyword">for</span> book_url <span class="keyword">in</span> book_urls:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                res = visit(book_url)  <span class="comment"># 对那一页的一本书进行访问</span></span><br><span class="line">                book = CrawlBook(res)  <span class="comment"># 建立一个书对象，data存放其信息，以json存储</span></span><br><span class="line">                save_to_mysql(book.data)  <span class="comment"># 将该书信息插入mysql中，继续第二本</span></span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                <span class="built_in">print</span>(e)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;歇一会QAQ，就2秒&#x27;</span>)</span><br><span class="line">                time.sleep(<span class="number">2</span>)</span><br><span class="line">    <span class="comment"># 换到另外一个标签的第1页</span></span><br></pre></td></tr></table></figure><h3 id="爬取过程截图"><a href="#爬取过程截图" class="headerlink" title="爬取过程截图"></a>爬取过程截图</h3><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://horacehhtbucket.oss-cn-guangzhou.aliyuncs.com/img/image-20210521231810540.png"                      alt="image-20210521231810540"                ></p><p>这是我保存下来的截图之一，可见，存储数据时经常会遇到一些我们意向不到的报错，所以<strong>异常处理真的很重要啊！！！</strong></p><p><strong>少年，一定要学会用try-except语句啊！！！你刚开始学异常处理觉得没什么用，等你遭受过毒打就知道有多重要了！！！</strong></p><p>这是数据库中的部分数据（用了navicat）</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://horacehhtbucket.oss-cn-guangzhou.aliyuncs.com/img/image-20210521233153437.png"                      alt="image-20210521233153437"                ></p><h2 id="下载书籍图片"><a href="#下载书籍图片" class="headerlink" title="下载书籍图片"></a>下载书籍图片</h2><p>因为我考核有一个界面要做书籍信息的展示，要贴书的封面图，所以还要下载下来。</p><p>我们数据库中存储的字段里有图片链接（cover_url），我们提取出来，对每个链接进行访问，进行图片的下载。</p><p>直接贴代码：（visit函数跟之前是一样的）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    sql_f = <span class="string">&quot;SELECT * FROM books&quot;</span> <span class="comment"># 选取所有书</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        cur.execute(sql_f)</span><br><span class="line">        results = cur.fetchall()  <span class="comment"># 获得匹配结果</span></span><br><span class="line">        columnDes = cur.description  <span class="comment"># 获取连接对象的描述信息</span></span><br><span class="line">        columnNames = [columnDes[i][<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(columnDes))]  <span class="comment"># 获取列名</span></span><br><span class="line">        <span class="comment"># 得到的results为二维元组，逐行取出，转化为列表，再转化为df</span></span><br><span class="line">        books_df = pd.DataFrame([<span class="built_in">list</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> results], columns=columnNames)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(e)</span><br><span class="line">    books_df = books_df.dropna(axis=<span class="number">0</span>, subset=[<span class="string">&quot;cover_url&quot;</span>])  <span class="comment"># 去除cover_url有缺失值的行</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;books_cover&#x27;</span> <span class="keyword">in</span> os.listdir(os.getcwd()):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        os.mkdir(<span class="string">&#x27;books_cover&#x27;</span>)  <span class="comment"># 创建books_cover目录，负责存放书籍封面图</span></span><br><span class="line">    os.chdir(<span class="string">&#x27;books_cover&#x27;</span>)  <span class="comment"># 切换到books_cover目录</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(books_df)):</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            res = visit(books_df.iloc[i][<span class="number">10</span>])  <span class="comment"># 访问图片链接</span></span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(e)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;歇一会吧QAQ，就2秒&quot;</span>)</span><br><span class="line">            time.sleep(<span class="number">2</span>)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;正在保存第&quot;</span> + <span class="built_in">str</span>(i + <span class="number">1</span>) + <span class="string">&quot;张图片...&quot;</span>)</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(books_df.iloc[i][<span class="number">0</span>] + <span class="string">&#x27;.jpg&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                f.write(res.content)  <span class="comment"># 以书名为文件名下载图片</span></span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;保存失败!&#x27;</span>)</span><br><span class="line">    conn.close()  <span class="comment"># 关闭python与mysql的连接</span></span><br></pre></td></tr></table></figure><p>示例截图：</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://horacehhtbucket.oss-cn-guangzhou.aliyuncs.com/img/image-20210521234006967.png"                      alt="image-20210521234006967"                ></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://horacehhtbucket.oss-cn-guangzhou.aliyuncs.com/img/image-20210521234106695.png"                      alt="image-20210521234106695"                ></p><h2 id="整体代码"><a href="#整体代码" class="headerlink" title="整体代码"></a>整体代码</h2><h3 id="crawl-book文件"><a href="#crawl-book文件" class="headerlink" title="crawl_book文件"></a>crawl_book文件</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 库导入部分</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CrawlBook</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, res</span>):</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            self.soup = BeautifulSoup(res.text, <span class="string">&#x27;lxml&#x27;</span>)  <span class="comment"># 初始化</span></span><br><span class="line">            self.html = etree.HTML(res.text)  <span class="comment"># 初始化</span></span><br><span class="line">            self.data = <span class="built_in">dict</span>()  <span class="comment"># 生成一个空字典</span></span><br><span class="line">            self.get_book_name()</span><br><span class="line">            self.get_author()</span><br><span class="line">            self.get_many()</span><br><span class="line">            self.get_score()</span><br><span class="line">            self.get_rating_num()</span><br><span class="line">            self.get_content()</span><br><span class="line">            self.get_image()</span><br><span class="line">            self.get_readers()</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            self.data.setdefault(<span class="string">&#x27;author&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">            self.data.setdefault(<span class="string">&#x27;出版社:&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">            self.data.setdefault(<span class="string">&#x27;出版年:&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">            self.data.setdefault(<span class="string">&#x27;页数:&#x27;</span>, <span class="string">&#x27;0&#x27;</span>)</span><br><span class="line">            self.data.setdefault(<span class="string">&#x27;定价:&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">            self.data.setdefault(<span class="string">&#x27;ISBN:&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">            self.data.setdefault(<span class="string">&#x27;score&#x27;</span>, <span class="number">0.0</span>)</span><br><span class="line">            self.data.setdefault(<span class="string">&#x27;rating_num&#x27;</span>, <span class="number">0</span>)</span><br><span class="line">            self.data.setdefault(<span class="string">&#x27;content_introduction&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">            self.data.setdefault(<span class="string">&#x27;readers&#x27;</span>, <span class="string">&#x27;[]&#x27;</span>)</span><br><span class="line">            <span class="built_in">print</span>(e)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_book_name</span>(<span class="params">self</span>):</span></span><br><span class="line">        book_name = self.soup.find(name=<span class="string">&#x27;span&#x27;</span>, attrs=&#123;<span class="string">&#x27;property&#x27;</span>: <span class="string">&#x27;v:itemreviewed&#x27;</span>&#125;).string</span><br><span class="line">        <span class="comment"># 找到节点名为span，属性property值为itemreviewd的节点，.string获取其文本内容</span></span><br><span class="line">        self.data.setdefault(<span class="string">&#x27;book_name&#x27;</span>, book_name)  <span class="comment"># 将其添加到字典中，下面的解析方法大同小异</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_author</span>(<span class="params">self</span>):</span></span><br><span class="line">        author = self.soup.find(name=<span class="string">&#x27;span&#x27;</span>, text=re.<span class="built_in">compile</span>(<span class="string">&#x27;.*?作者.*?&#x27;</span>)).next_sibling.next_sibling\</span><br><span class="line">            .string.replace(<span class="string">&#x27;\n&#x27;</span>, <span class="string">&#x27;&#x27;</span>).replace(<span class="string">&#x27; &#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">        self.data.setdefault(<span class="string">&#x27;author&#x27;</span>, author)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_many</span>(<span class="params">self</span>):</span></span><br><span class="line">        want_to_spider = [<span class="string">&#x27;出版社:&#x27;</span>, <span class="string">&#x27;出版年:&#x27;</span>, <span class="string">&#x27;页数:&#x27;</span>, <span class="string">&#x27;定价:&#x27;</span>, <span class="string">&#x27;ISBN:&#x27;</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> self.soup.find_all(name=<span class="string">&#x27;span&#x27;</span>, attrs=&#123;<span class="string">&#x27;class&#x27;</span>: <span class="string">&#x27;pl&#x27;</span>&#125;):</span><br><span class="line">            <span class="keyword">if</span> i.string <span class="keyword">in</span> want_to_spider:</span><br><span class="line">                self.data.setdefault(i.string, i.next_sibling.replace(<span class="string">&#x27; &#x27;</span>, <span class="string">&#x27;&#x27;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_score</span>(<span class="params">self</span>):</span></span><br><span class="line">        score = <span class="built_in">float</span>(self.soup.find(name=<span class="string">&#x27;strong&#x27;</span>, attrs=&#123;<span class="string">&#x27;property&#x27;</span>: <span class="string">&#x27;v:average&#x27;</span>&#125;).string)</span><br><span class="line">        self.data.setdefault(<span class="string">&#x27;score&#x27;</span>, score)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_rating_num</span>(<span class="params">self</span>):</span></span><br><span class="line">        rating_num = <span class="built_in">int</span>(self.soup.find(name=<span class="string">&#x27;span&#x27;</span>, attrs=&#123;<span class="string">&#x27;property&#x27;</span>: <span class="string">&#x27;v:votes&#x27;</span>&#125;).string)</span><br><span class="line">        self.data.setdefault(<span class="string">&#x27;rating_num&#x27;</span>, rating_num)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_content</span>(<span class="params">self</span>):</span></span><br><span class="line">        l = <span class="string">&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> self.soup.find(name=<span class="string">&#x27;div&#x27;</span>, attrs=&#123;<span class="string">&#x27;class&#x27;</span>: <span class="string">&#x27;intro&#x27;</span>&#125;).contents:</span><br><span class="line">                l += <span class="built_in">str</span>(i)</span><br><span class="line">            self.data.setdefault(<span class="string">&#x27;content_introduction&#x27;</span>, l.strip())</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(e)</span><br><span class="line">            self.data.setdefault(<span class="string">&#x27;content_introduction&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_image</span>(<span class="params">self</span>):</span></span><br><span class="line">        image_url = self.soup.find(name=<span class="string">&#x27;img&#x27;</span>, attrs=&#123;<span class="string">&#x27;rel&#x27;</span>: <span class="string">&#x27;v:photo&#x27;</span>&#125;)[<span class="string">&#x27;src&#x27;</span>]  <span class="comment"># 获取节点的src属性值</span></span><br><span class="line">        self.data.setdefault(<span class="string">&#x27;cover_url&#x27;</span>, image_url)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_readers</span>(<span class="params">self</span>):</span></span><br><span class="line">        readers = <span class="built_in">str</span>(self.html.xpath(<span class="string">&#x27;//*[@id=&quot;collector&quot;]//div/div[2]/a/@href&#x27;</span>))  </span><br><span class="line">        <span class="comment"># 这里用的是xpath的解析方法，获取所有属性值为collector下的所有div节点下的第二个div节点的a节点的href属性值</span></span><br><span class="line">        self.data.setdefault(<span class="string">&#x27;readers&#x27;</span>, readers)</span><br></pre></td></tr></table></figure><h3 id="crawl文件"><a href="#crawl文件" class="headerlink" title="crawl文件"></a>crawl文件</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> crawl_book <span class="keyword">import</span> CrawlBook</span><br><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"></span><br><span class="line">conn = pymysql.connect(  <span class="comment"># 连接本地数据库</span></span><br><span class="line">        host=<span class="string">&quot;localhost&quot;</span>,</span><br><span class="line">        user=<span class="string">&quot;root&quot;</span>,  <span class="comment"># 要填root</span></span><br><span class="line">        password=<span class="string">&quot;htht0928&quot;</span>,  <span class="comment"># 填上自己的密码</span></span><br><span class="line">        database=<span class="string">&quot;doubanbook&quot;</span>,  <span class="comment"># 数据库名</span></span><br><span class="line">        charset=<span class="string">&quot;utf8&quot;</span></span><br><span class="line">    )</span><br><span class="line">cur = conn.cursor()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请求头</span></span><br><span class="line">headers = [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;Connection&#x27;</span>: <span class="string">&#x27;close&#x27;</span>&#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&quot;Mozilla/5.0 (X11; U; Linux x86_64; zh-CN; rv:1.9.2.10) Gecko/20100922 Ubuntu/10.10 (maverick) Firefox/3.6.10&quot;</span>,</span><br><span class="line">        <span class="string">&#x27;Connection&#x27;</span>: <span class="string">&#x27;close&#x27;</span>&#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36 OPR/26.0.1656.60&quot;</span>,</span><br><span class="line">        <span class="string">&#x27;Connection&#x27;</span>: <span class="string">&#x27;close&#x27;</span>&#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&quot;Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; .NET4.0E; QQBrowser/7.0.3698.400)&quot;</span>,</span><br><span class="line">        <span class="string">&#x27;Connection&#x27;</span>: <span class="string">&#x27;close&#x27;</span>&#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&quot;Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; Trident/4.0; SV1; QQDownload 732; .NET4.0C; .NET4.0E; SE 2.X MetaSr 1.0)&quot;</span>,</span><br><span class="line">        <span class="string">&#x27;Connection&#x27;</span>: <span class="string">&#x27;close&#x27;</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko&quot;</span>,</span><br><span class="line">        <span class="string">&#x27;Connection&#x27;</span>: <span class="string">&#x27;close&#x27;</span>&#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Maxthon/4.4.3.4000 Chrome/30.0.1599.101 Safari/537.36&quot;</span>,</span><br><span class="line">        <span class="string">&#x27;Connection&#x27;</span>: <span class="string">&#x27;close&#x27;</span>&#125;</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line"><span class="comment"># http代理接入服务器地址端口</span></span><br><span class="line">proxyHost = <span class="string">&quot;http-proxy-t3.dobel.cn&quot;</span></span><br><span class="line">proxyPort = <span class="string">&quot;9180&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#账号密码</span></span><br><span class="line">proxyUser = <span class="string">&quot;HORACEC0JB9ONL0&quot;</span></span><br><span class="line">proxyPass = <span class="string">&quot;t7PG9y5o&quot;</span></span><br><span class="line"></span><br><span class="line">proxyMeta = <span class="string">&quot;http://%(user)s:%(pass)s@%(host)s:%(port)s&quot;</span> % &#123;</span><br><span class="line">    <span class="string">&quot;host&quot;</span> : proxyHost,</span><br><span class="line">    <span class="string">&quot;port&quot;</span> : proxyPort,</span><br><span class="line">    <span class="string">&quot;user&quot;</span> : proxyUser,</span><br><span class="line">    <span class="string">&quot;pass&quot;</span> : proxyPass,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">proxies = &#123;</span><br><span class="line">    <span class="string">&quot;http&quot;</span>  : proxyMeta,</span><br><span class="line">    <span class="string">&quot;https&quot;</span> : proxyMeta,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">visit</span>(<span class="params">targetUrl</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;访问网址，返回响应&quot;&quot;&quot;</span></span><br><span class="line">    session = requests.Session()</span><br><span class="line">    session.keep_alive = <span class="literal">False</span></span><br><span class="line">    res = session.get(targetUrl, proxies=proxies, headers=random.choice(headers))</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">crawl_tags</span>(<span class="params">page</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;获取每个标签网页的page页&quot;&quot;&quot;</span></span><br><span class="line">    url = <span class="string">&#x27;https://book.douban.com/tag/?view=type&amp;icn=index-sorttags-all&#x27;</span></span><br><span class="line">    res = visit(url)</span><br><span class="line">    html = etree.HTML(res.text)</span><br><span class="line">    tags = html.xpath(<span class="string">&#x27;//*[@id=&quot;content&quot;]//tr/td/a/text()&#x27;</span>)</span><br><span class="line">    pages_url = [<span class="string">&#x27;https://book.douban.com/tag/&#x27;</span> + tag + <span class="string">&#x27;?=&#x27;</span> + <span class="built_in">str</span>((page-<span class="number">1</span>)*<span class="number">20</span>) + <span class="string">&#x27;&amp;type=T&#x27;</span> <span class="keyword">for</span> tag <span class="keyword">in</span> tags]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;已获取&#x27;</span> + <span class="built_in">str</span>(<span class="built_in">len</span>(pages_url)) + <span class="string">&#x27;个标签网页&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> pages_url</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_book_urls</span>(<span class="params">tag_url</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;获取每个标签网页中的第一页，20本书&quot;&quot;&quot;</span></span><br><span class="line">    l = <span class="built_in">set</span>()</span><br><span class="line">    i = <span class="number">20</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        res = visit(tag_url)</span><br><span class="line">        html = etree.HTML(res.text)</span><br><span class="line">        books_urls = html.xpath(<span class="string">&#x27;//*[@id=&quot;subject_list&quot;]/ul//li/div[2]/h2/a/@href&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> book_url <span class="keyword">in</span> books_urls:</span><br><span class="line">            l.add(book_url)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;已获取%d本书&#x27;</span> % i)</span><br><span class="line">        i += <span class="number">20</span></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(e)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;要停一会!休息2秒&#x27;</span>)</span><br><span class="line">        time.sleep(<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">list</span>(l)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_to_mysql</span>(<span class="params">data</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;data是书籍的信息，json格式，要插入到release这个表&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    book_name = data.get(<span class="string">&#x27;book_name&#x27;</span>)</span><br><span class="line">    author = data.get(<span class="string">&#x27;author&#x27;</span>)</span><br><span class="line">    press = data.get(<span class="string">&#x27;出版社:&#x27;</span>)</span><br><span class="line">    publishing_year = data.get(<span class="string">&#x27;出版年:&#x27;</span>)</span><br><span class="line">    page_num = data.get(<span class="string">&#x27;页数:&#x27;</span>)</span><br><span class="line">    price = data.get(<span class="string">&#x27;定价:&#x27;</span>)</span><br><span class="line">    ISBN = data.get(<span class="string">&#x27;ISBN:&#x27;</span>)</span><br><span class="line">    score = data.get(<span class="string">&#x27;score&#x27;</span>)</span><br><span class="line">    rating_num = data.get(<span class="string">&#x27;rating_num&#x27;</span>)</span><br><span class="line">    content_introduction = data.get(<span class="string">&#x27;content_introduction&#x27;</span>)</span><br><span class="line">    cover_url = data.get(<span class="string">&#x27;cover_url&#x27;</span>)</span><br><span class="line">    readers = data.get(<span class="string">&#x27;readers&#x27;</span>)</span><br><span class="line">    insert_data = (book_name, author, press, publishing_year, score, rating_num, page_num, price, ISBN,</span><br><span class="line">                   content_introduction, cover_url, readers)</span><br><span class="line">    insert_sql = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        INSERT INTO books(book_name, author, press, publishing_year, score, rating_num, page_num, price,</span></span><br><span class="line"><span class="string">        ISBN, content_introduction, cover_url, readers)</span></span><br><span class="line"><span class="string">        VALUES(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># 执行sql语句</span></span><br><span class="line">        cur.execute(insert_sql, insert_data)</span><br><span class="line">        <span class="comment"># 提交执行</span></span><br><span class="line">        conn.commit()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;《&#x27;</span> + book_name + <span class="string">&#x27;》&#x27;</span> + <span class="string">&#x27;信息已存储成功!&#x27;</span>)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(e)</span><br><span class="line">        conn.rollback()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;存储失败!&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    tags_url = crawl_tags(<span class="number">4</span>)  <span class="comment"># 获取第一页</span></span><br><span class="line">    <span class="keyword">for</span> page <span class="keyword">in</span> tags_url:</span><br><span class="line">        book_urls = get_book_urls(page)  <span class="comment"># 某个标签的第一页的书链接</span></span><br><span class="line">        <span class="keyword">for</span> book_url <span class="keyword">in</span> book_urls:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                res = visit(book_url)  <span class="comment"># 对那一页的一本书进行访问</span></span><br><span class="line">                book = CrawlBook(res)  <span class="comment"># 建立一个书对象，data存放其信息，以json存储</span></span><br><span class="line">                save_to_mysql(book.data)  <span class="comment"># 将该书信息插入mysql中，继续第二本</span></span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                <span class="built_in">print</span>(e)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;歇一会QAQ，就2秒&#x27;</span>)</span><br><span class="line">                time.sleep(<span class="number">3</span>)</span><br><span class="line">    <span class="comment"># 换到另外一个标签的第1页</span></span><br><span class="line">    start = <span class="number">20</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">60</span>):</span><br><span class="line">        new = start + i*<span class="number">20</span></span><br><span class="line">        url = <span class="string">&#x27;https://book.douban.com/tag/%E6%97%85%E8%A1%8C?start=&#x27;</span> + <span class="built_in">str</span>(new) + <span class="string">&#x27;&amp;type=T&#x27;</span></span><br><span class="line">        book_urls = get_book_urls(url)</span><br><span class="line">        <span class="keyword">for</span> book_url <span class="keyword">in</span> book_urls:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                res = visit(book_url)</span><br><span class="line">                book = CrawlBook(res)</span><br><span class="line">                save_to_mysql(book.data)</span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                <span class="built_in">print</span>(e)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;歇一会QAQ，就2秒&#x27;</span>)</span><br><span class="line">                time.sleep(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;爬取完成!&#x27;</span>)</span><br><span class="line">    conn.close()  <span class="comment"># 关闭连接，不然多了，数据库会锁</span></span><br></pre></td></tr></table></figure><h3 id="download-image文件"><a href="#download-image文件" class="headerlink" title="download_image文件"></a>download_image文件</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">conn = pymysql.connect(  <span class="comment"># 连接本地数据库</span></span><br><span class="line">        host=<span class="string">&quot;localhost&quot;</span>,</span><br><span class="line">        user=<span class="string">&quot;root&quot;</span>,  <span class="comment"># 要填root</span></span><br><span class="line">        password=<span class="string">&quot;htht0928&quot;</span>,  <span class="comment"># 填上自己的密码</span></span><br><span class="line">        database=<span class="string">&quot;doubanbook&quot;</span>,  <span class="comment"># 数据库名</span></span><br><span class="line">        charset=<span class="string">&quot;utf8&quot;</span></span><br><span class="line">    )</span><br><span class="line">cur = conn.cursor()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请求头</span></span><br><span class="line">headers = [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;Connection&#x27;</span>: <span class="string">&#x27;close&#x27;</span>&#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&quot;Mozilla/5.0 (X11; U; Linux x86_64; zh-CN; rv:1.9.2.10) Gecko/20100922 Ubuntu/10.10 (maverick) Firefox/3.6.10&quot;</span>,</span><br><span class="line">        <span class="string">&#x27;Connection&#x27;</span>: <span class="string">&#x27;close&#x27;</span>&#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36 OPR/26.0.1656.60&quot;</span>,</span><br><span class="line">        <span class="string">&#x27;Connection&#x27;</span>: <span class="string">&#x27;close&#x27;</span>&#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&quot;Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; .NET4.0E; QQBrowser/7.0.3698.400)&quot;</span>,</span><br><span class="line">        <span class="string">&#x27;Connection&#x27;</span>: <span class="string">&#x27;close&#x27;</span>&#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&quot;Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; Trident/4.0; SV1; QQDownload 732; .NET4.0C; .NET4.0E; SE 2.X MetaSr 1.0)&quot;</span>,</span><br><span class="line">        <span class="string">&#x27;Connection&#x27;</span>: <span class="string">&#x27;close&#x27;</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko&quot;</span>,</span><br><span class="line">        <span class="string">&#x27;Connection&#x27;</span>: <span class="string">&#x27;close&#x27;</span>&#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Maxthon/4.4.3.4000 Chrome/30.0.1599.101 Safari/537.36&quot;</span>,</span><br><span class="line">        <span class="string">&#x27;Connection&#x27;</span>: <span class="string">&#x27;close&#x27;</span>&#125;</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line"><span class="comment"># http代理接入服务器地址端口</span></span><br><span class="line">proxyHost = <span class="string">&quot;http-proxy-t3.dobel.cn&quot;</span></span><br><span class="line">proxyPort = <span class="string">&quot;9180&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#账号密码</span></span><br><span class="line">proxyUser = <span class="string">&quot;HORACEC0JB9ONL0&quot;</span></span><br><span class="line">proxyPass = <span class="string">&quot;t7PG9y5o&quot;</span></span><br><span class="line"></span><br><span class="line">proxyMeta = <span class="string">&quot;http://%(user)s:%(pass)s@%(host)s:%(port)s&quot;</span> % &#123;</span><br><span class="line">    <span class="string">&quot;host&quot;</span> : proxyHost,</span><br><span class="line">    <span class="string">&quot;port&quot;</span> : proxyPort,</span><br><span class="line">    <span class="string">&quot;user&quot;</span> : proxyUser,</span><br><span class="line">    <span class="string">&quot;pass&quot;</span> : proxyPass,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">proxies = &#123;</span><br><span class="line">    <span class="string">&quot;http&quot;</span>  : proxyMeta,</span><br><span class="line">    <span class="string">&quot;https&quot;</span> : proxyMeta,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">visit</span>(<span class="params">targetUrl</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;访问网址，返回响应&quot;&quot;&quot;</span></span><br><span class="line">    session = requests.Session()</span><br><span class="line">    session.keep_alive = <span class="literal">False</span></span><br><span class="line">    res = session.get(targetUrl, proxies=proxies, headers=random.choice(headers))</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    sql_f = <span class="string">&quot;SELECT * FROM books&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        cur.execute(sql_f)</span><br><span class="line">        results = cur.fetchall()</span><br><span class="line">        columnDes = cur.description  <span class="comment"># 获取连接对象的描述信息</span></span><br><span class="line">        columnNames = [columnDes[i][<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(columnDes))]  <span class="comment"># 获取列名</span></span><br><span class="line">        <span class="comment"># 得到的results为二维元组，逐行取出，转化为列表，再转化为df</span></span><br><span class="line">        books_df = pd.DataFrame([<span class="built_in">list</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> results], columns=columnNames)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(e)</span><br><span class="line">    books_df = books_df.dropna(axis=<span class="number">0</span>, subset=[<span class="string">&quot;cover_url&quot;</span>])  <span class="comment"># 去除cover_url有缺失值的行</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;books_cover&#x27;</span> <span class="keyword">in</span> os.listdir(os.getcwd()):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        os.mkdir(<span class="string">&#x27;books_cover&#x27;</span>)</span><br><span class="line">    os.chdir(<span class="string">&#x27;books_cover&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(books_df)):</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            res = visit(books_df.iloc[i][<span class="number">10</span>])</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(e)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;歇一会吧QAQ，就2秒&quot;</span>)</span><br><span class="line">            time.sleep(<span class="number">2</span>)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;正在保存第&quot;</span> + <span class="built_in">str</span>(i + <span class="number">1</span>) + <span class="string">&quot;张图片...&quot;</span>)</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(books_df.iloc[i][<span class="number">0</span>] + <span class="string">&#x27;.jpg&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                f.write(res.content)</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;保存失败!&#x27;</span>)</span><br><span class="line">    conn.close()</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这是我<strong>5.14一天</strong>的爬虫过程（一周后的回顾）…还真是人不逼自己一把，就不知道自己的潜力有多大。</p><p>这是代理帮我统计我一天的请求次数，1w8，我也没想到hhh</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://horacehhtbucket.oss-cn-guangzhou.aliyuncs.com/img/image-20210521234721368.png"                      alt="image-20210521234721368"                ></p><p>其中遇到了很多的困难，数据插入问题，报错proxyerror，mysql锁住了…所幸都解决了</p><p>解决的方式或是查阅资料，或是灵光乍现…</p><p>那一天太累了，真的太累了，出现问题-&gt;解决问题-&gt;出现问题-&gt;解决问题-&gt;…</p><p>感谢我的好朋友愿意陪我聊天<del>（当我的文件传输助手）</del>，在我低落的时候给予我精神上的鼓励</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://horacehhtbucket.oss-cn-guangzhou.aliyuncs.com/img/image-20210521235019716.png"                      alt="image-20210521235019716"                ></p><p>龙哥，我是你的粉丝啊！（<del>飞踢</del>飞扑）</p><p>那么，此次的爬虫回顾结束🔚啦。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;设置代理爬取豆瓣书籍&quot;&gt;&lt;a href=&quot;#设置代理爬取豆瓣书籍&quot; class=&quot;headerlink&quot; title=&quot;设置代理爬取豆瓣书籍&quot;&gt;&lt;/a&gt;设置代理爬取豆瓣书籍&lt;/h1&gt;&lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerli</summary>
      
    
    
    
    <category term="python" scheme="https://horacehht.github.io/categories/python/"/>
    
    
    <category term="爬虫" scheme="https://horacehht.github.io/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>利用hexo框架搭建个人博客</title>
    <link href="https://horacehht.github.io/2021/05/29/%E5%88%A9%E7%94%A8hexo%E6%A1%86%E6%9E%B6%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"/>
    <id>https://horacehht.github.io/2021/05/29/%E5%88%A9%E7%94%A8hexo%E6%A1%86%E6%9E%B6%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/</id>
    <published>2021-05-29T06:25:10.000Z</published>
    <updated>2021-05-29T15:37:37.387Z</updated>
    
    <content type="html"><![CDATA[<h1 id="利用hexo框架搭建个人博客"><a href="#利用hexo框架搭建个人博客" class="headerlink" title="利用hexo框架搭建个人博客"></a>利用hexo框架搭建个人博客</h1><h2 id="安装git"><a href="#安装git" class="headerlink" title="安装git"></a>安装git</h2><p>由于我之前安装了就不说了</p><p>可以百度搜索🔍git官网。git是可以一直无脑下一步安装的。相信这不会难倒聪明的你</p><h2 id="安装nodejs"><a href="#安装nodejs" class="headerlink" title="安装nodejs"></a>安装nodejs</h2><p>进入<a class="link"   href="https://nodejs.org/en/download" >官网<i class="fas fa-external-link-alt"></i></a>选择对应的版本进行下载</p><p>安装时一路next即可（路    径你自己选）</p><p>安装成功后，win+R，输入cmd进入命令行，输入</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">node -v</span><br><span class="line">npm -v</span><br></pre></td></tr></table></figure><p>检查是否安装成功</p><p>如果呈现这样的就界面，则表示安装成功</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://horacehhtbucket.oss-cn-guangzhou.aliyuncs.com/img/image-20210525205236141.png"                      alt="image-20210525205236141"                ></p><p>另外，可以用git bash代替命令行来敲命令</p><h2 id="安装hexo"><a href="#安装hexo" class="headerlink" title="安装hexo"></a>安装hexo</h2><p>自己创建一个文件夹，我这里新建了一个blog文件夹，点进去后右键git bash here</p><p>git bash内输入<code>hexo init name</code>，这里的name你爱怎么填怎么填</p><p>过程中可能会报错<code>OpenSSL SSL_read: Connection was reset, errno 10054</code></p><p>最有可能是<strong>网络不稳定</strong>，github经常这样，至于原因，大家懂得都懂，有时候科学上网之后也是这样。</p><p>这里我输入了<code>hexo init Horace</code></p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://horacehhtbucket.oss-cn-guangzhou.aliyuncs.com/img/image-20210525211253771.png"                      alt="image-20210525211253771" style="zoom: 80%;"                 ><p>出现这样的界面即初始化成功</p><p>随后，<code>cd Horace</code>进入刚刚初始化的文件夹内，输入<code>npm install</code></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://horacehhtbucket.oss-cn-guangzhou.aliyuncs.com/img/image-20210525211800200.png"                      alt="image-20210525211800200"                ></p><p>随后输入</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo g</span><br><span class="line">hexo server</span><br></pre></td></tr></table></figure><p>或是输入<code>hexo s</code></p><p>打开hexo服务，浏览器输入<code>localhost:4000</code>，即可看到刚刚创建的博客了。长这样子：</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://horacehhtbucket.oss-cn-guangzhou.aliyuncs.com/img/image-20210525211944802.png"                      alt="image-20210525211944802"                ></p><p>可以通过Ctrl+C停止hexo服务。</p><p>停止服务后，再输入<code>localhost:4000</code>就登不上网站了。</p><h2 id="部署到云端"><a href="#部署到云端" class="headerlink" title="部署到云端"></a>部署到云端</h2><p>这里可以看到，我们输入的网址是<code>localhost:4000</code>，并不是个静态链接</p><p>而我们搭个人博客本身就是想别人来看的，如果别人都点不进来，那有什么意义啊？</p><p>所以，<strong>要让我们的个人博客可以被别人访问到</strong>，我们可以<strong>将我们的网站部署到云端</strong>（不是唯一的方式）</p><p>这里就让github托管我们的博客。</p><h3 id="创建github账户与创建对应仓库"><a href="#创建github账户与创建对应仓库" class="headerlink" title="创建github账户与创建对应仓库"></a>创建github账户与创建对应仓库</h3><p>注册一个github账户，创建（new）一个仓库，仓库名叫<code>用户名+.github.io</code></p><p>我的用户名是horacehht，因此创建一个<code>horacehht.github.io</code>的仓库</p><h3 id="生成SSH添加到github"><a href="#生成SSH添加到github" class="headerlink" title="生成SSH添加到github"></a>生成SSH添加到github</h3><p>参考<a class="link"   href="https://www.liaoxuefeng.com/wiki/896043488029600/896954117292416" >廖雪峰博客git文章<i class="fas fa-external-link-alt"></i></a></p><h3 id="将hexo部署到云端"><a href="#将hexo部署到云端" class="headerlink" title="将hexo部署到云端"></a>将hexo部署到云端</h3><p>通过<code>npm install hexo-deployer-git --save</code>命令下载部署的相应插件</p><p>然后</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hexo clean</span><br><span class="line">hexo generate</span><br><span class="line">hexo deploy</span><br></pre></td></tr></table></figure><p>但是之后访问<code>http://horacehht.github.io</code>报错404，说<code>There isn&#39;t a GitHub Pages site here.</code></p><p>最后通过github page的官方文档得知，如果要作为一个Github Pages仓库，需满足三个条件：</p><ul><li>仓库名为<code>用户名+github.io</code></li><li>仓库应设为public（公开）</li><li>仓库内要创建一个<strong>README</strong>文档</li></ul><h2 id="hexo的基本命令"><a href="#hexo的基本命令" class="headerlink" title="hexo的基本命令"></a>hexo的基本命令</h2><table><thead><tr><th align="center">命令</th><th align="center">作用</th></tr></thead><tbody><tr><td align="center">Hexo init</td><td align="center">初始化博客</td></tr><tr><td align="center">Hexo s</td><td align="center">运行博客</td></tr><tr><td align="center">Hexo n title</td><td align="center">创建一篇新的文章，title为文章标题</td></tr><tr><td align="center">Hexo c(clean)</td><td align="center">清理文件</td></tr><tr><td align="center">Hexo g(GENERATE)</td><td align="center">生成静态文件</td></tr><tr><td align="center">Hexo d(deploy)</td><td align="center">部署博客</td></tr></tbody></table><img                       lazyload                     src="/images/loading.svg"                     data-src="https://horacehhtbucket.oss-cn-guangzhou.aliyuncs.com/img/image-20210527152411806.png"                      alt="image-20210527152411806"                  ><p>hexo项目的_config.yml是<strong>整个hexo项目的总配置文件</strong>，如果需要配置主题，则还有对应主题的配置文件。</p><h2 id="主题挑选"><a href="#主题挑选" class="headerlink" title="主题挑选"></a>主题挑选</h2><p>挑选主题中…selecting</p><p>1.Yun主题是我最喜欢的一个主题，但是因为一些特殊原因，怕审美疲劳，就不用了。demo：<a class="link"   href="https://www.yunyoujun.cn/" >https://www.yunyoujun.cn/<i class="fas fa-external-link-alt"></i></a></p><p>github地址：<a class="link"   href="https://github.com/YunYouJun/hexo-theme-yun" >https://github.com/YunYouJun/hexo-theme-yun<i class="fas fa-external-link-alt"></i></a></p><p>2.Anatole主题也可，很简洁，但不喜欢。demo：<a class="link"   href="https://www.jixian.io/" >https://www.jixian.io/<i class="fas fa-external-link-alt"></i></a></p><p>github地址：<a class="link"   href="https://github.com/mrcore/hexo-theme-Anatole-Core" >https://github.com/mrcore/hexo-theme-Anatole-Core<i class="fas fa-external-link-alt"></i></a></p><p>3.Ayer主题。很全面的一个主题。demo：<a class="link"   href="https://shen-yu.gitee.io/" >https://shen-yu.gitee.io/<i class="fas fa-external-link-alt"></i></a></p><p>github地址：<a class="link"   href="https://github.com/Shen-Yu/hexo-theme-ayer" >https://github.com/Shen-Yu/hexo-theme-ayer<i class="fas fa-external-link-alt"></i></a></p><p>感觉非常不错。</p><p>4.Particle主题。简洁。但文章没有目录。demo：<a class="link"   href="https://korilin.com/" >https://korilin.com/<i class="fas fa-external-link-alt"></i></a></p><p>github地址：<a class="link"   href="https://github.com/korilin/hexo-theme-particle" >https://github.com/korilin/hexo-theme-particle<i class="fas fa-external-link-alt"></i></a></p><p>5.shoka主题。交互性强，字体好看，引用块好看。demo：<a class="link"   href="https://shoka.lostyu.me/" >https://shoka.lostyu.me/<i class="fas fa-external-link-alt"></i></a></p><p>github地址：<a class="link"   href="https://github.com/amehime/hexo-theme-shoka" >https://github.com/amehime/hexo-theme-shoka<i class="fas fa-external-link-alt"></i></a></p><p>有点花</p><p>6.Keep主题。切换自然。主页面简洁。demo：<a class="link"   href="https://xpoet.cn/" >https://xpoet.cn/<i class="fas fa-external-link-alt"></i></a></p><p>github地址：<a class="link"   href="https://github.com/XPoet/hexo-theme-keep" >https://github.com/XPoet/hexo-theme-keep<i class="fas fa-external-link-alt"></i></a></p><p><strong>最终选定Keep这个主题！</strong>简洁又好看 </p><h2 id="使用Keep主题"><a href="#使用Keep主题" class="headerlink" title="使用Keep主题"></a>使用Keep主题</h2><p>注：配置文件有两个：总配置文件，主题配置文件。下文提到时注意区分</p><h3 id="安装主题"><a href="#安装主题" class="headerlink" title="安装主题"></a>安装主题</h3><p>在git bash中执行命令</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/XPoet/hexo-theme-keep themes/keep</span><br></pre></td></tr></table></figure><p>然后themes文件夹下出现我们想要的keep主题。</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://horacehhtbucket.oss-cn-guangzhou.aliyuncs.com/img/image-20210527220438580.png"                                     ></p><p>这个为<strong>主题配置文件</strong>（这里踩了一些坑，通过npm安装的没有这个文件夹）</p><h3 id="使用主题"><a href="#使用主题" class="headerlink" title="使用主题"></a>使用主题</h3><p>安装完成后，在 Hexo项目的<strong>总配置文件</strong>中将 <code>theme</code> 设置为 <code>keep</code>。</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">theme:</span> <span class="string">keep</span></span><br></pre></td></tr></table></figure><p>这个文件的路径为<code>name\_config.yml</code>，我的为<code>Horace\_config.yml</code></p><ul><li><p>keep会不定期更新版本，可通过如下命令更新Keep。</p></li><li><p>通过 npm 安装最新版本：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> hexo-site（hexo项目的位置）</span><br><span class="line">$ npm update hexo-theme-keep</span><br></pre></td></tr></table></figure><p>或</p></li><li><p>通过 git 更新到最新的 master 分支：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> themes/keep</span><br><span class="line">$ git pull</span><br></pre></td></tr></table></figure></li></ul><h3 id="配置指南"><a href="#配置指南" class="headerlink" title="配置指南"></a>配置指南</h3><p>复制<strong>主题配置文件</strong>。回到整个博客项目目录下的source文件夹，新建一个文件夹<code>_data</code>，将该文件粘贴进去</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://horacehhtbucket.oss-cn-guangzhou.aliyuncs.com/img/image-20210527220544858.png"                      alt="image-20210527220544858"                ></p><p><strong>将文件名更改为keep.yml</strong>，这很重要！</p><p>然后通过该文件来进行相应的修改即可实现对主题的配置！</p><p>这些是keep官方提供的配置资料，已经很全面了。</p><p><a class="link"   href="https://keep-docs.xpoet.cn/usage-tutorial/quick-start.html#%E5%AE%89%E8%A3%85" >https://keep-docs.xpoet.cn/usage-tutorial/quick-start.html#%E5%AE%89%E8%A3%85<i class="fas fa-external-link-alt"></i></a></p><p><a class="link"   href="https://keep-docs.xpoet.cn/usage-tutorial/configuration-guide.html#base-info" >https://keep-docs.xpoet.cn/usage-tutorial/configuration-guide.html#base-info<i class="fas fa-external-link-alt"></i></a></p><p><a class="link"   href="https://keep-docs.xpoet.cn/usage-tutorial/advanced.html" >https://keep-docs.xpoet.cn/usage-tutorial/advanced.html<i class="fas fa-external-link-alt"></i></a></p><p>这三个都是官方给的keep使用教程，分别为快速开始，配置指南和进阶使用，能满足大部分人的需求</p><hr><p>下面仅以base_info为例讲解，其他的配置项请参考官方资料</p><p><strong>base_info</strong>项</p><p>根据自己的内容进行填写</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">base_info:</span></span><br><span class="line">  <span class="attr">title:</span> <span class="string">Horaceの云端梦境</span></span><br><span class="line">  <span class="attr">author:</span> <span class="string">Horace</span></span><br><span class="line">  <span class="attr">url:</span> <span class="string">https://horacehht.github.io/</span>  <span class="comment"># 这里填上https://用户名.github.io如果自己注册了域名，就改成注册的</span></span><br><span class="line">  <span class="comment"># 图标的链接，可以用本地的图片，也可用图片链接，或者不填</span></span><br><span class="line">  <span class="attr">logo_img:</span> <span class="string">https://horacehhtbucket.oss-cn-guangzhou.aliyuncs.com/img/网站图标.jpg</span>  <span class="comment"># 这里我填了一个网页链接</span></span><br></pre></td></tr></table></figure><p>读者可以稍微了解<strong>图床</strong>，这里我购买了<a class="link"   href="https://cn.aliyun.com/" >阿里云<i class="fas fa-external-link-alt"></i></a>的<a class="link"   href="https://www.aliyun.com/product/oss?spm=5176.10695662.5694434980.1.22cd36b9sJuIpJ" >对象存储服务oss<i class="fas fa-external-link-alt"></i></a>作为图床放置我的图片</p><p>读者同样也可使用免费的图床：</p><ul><li><p><a class="link"   href="https://sm.ms/" >sm.ms<i class="fas fa-external-link-alt"></i></a></p></li><li><p><a class="link"   href="https://imgchr.com/" >路过图床<i class="fas fa-external-link-alt"></i></a></p></li></ul><p>利用阿里云作图床的文章：<a class="link"   href="https://zhuanlan.zhihu.com/p/138878534" >https://zhuanlan.zhihu.com/p/138878534<i class="fas fa-external-link-alt"></i></a></p><h3 id="小tips"><a href="#小tips" class="headerlink" title="小tips"></a>小tips</h3><p>文章都放在source的_posts文件夹下</p><p>文章如果<strong>想放在多个分类或多个标签下</strong>（前提是你开了分类和标签的功能），需要写成<code>[a,b,c]</code>的格式，如图：</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://horacehhtbucket.oss-cn-guangzhou.aliyuncs.com/img/image-20210529141615569.png"                      alt="image-20210529141615569"                ></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>之后每次写新文章，就进git bash中敲</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hexo clean</span><br><span class="line">hexo generate</span><br><span class="line">hexo deploy</span><br></pre></td></tr></table></figure><p>这样就能在自己的博客网站上看到新发布的文章了！</p><p>如果嫌麻烦的可以参考<a class="link"   href="https://juejin.cn/post/6943895271751286821" >这篇文章<i class="fas fa-external-link-alt"></i></a>进行<strong>自动部署</strong></p><p>我的博客网站为：<a href="https://horacehht.github.io/">https://horacehht.github.io</a></p><p>欢迎来访</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;利用hexo框架搭建个人博客&quot;&gt;&lt;a href=&quot;#利用hexo框架搭建个人博客&quot; class=&quot;headerlink&quot; title=&quot;利用hexo框架搭建个人博客&quot;&gt;&lt;/a&gt;利用hexo框架搭建个人博客&lt;/h1&gt;&lt;h2 id=&quot;安装git&quot;&gt;&lt;a href=&quot;#</summary>
      
    
    
    
    <category term="hexo" scheme="https://horacehht.github.io/categories/hexo/"/>
    
    
  </entry>
  
  <entry>
    <title>test</title>
    <link href="https://horacehht.github.io/2021/05/27/test/"/>
    <id>https://horacehht.github.io/2021/05/27/test/</id>
    <published>2021-05-27T14:42:55.000Z</published>
    <updated>2021-05-29T06:26:47.306Z</updated>
    
    <content type="html"><![CDATA[<h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><p>终于搞好了555</p><p>好开心<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.186ex" xmlns="http://www.w3.org/2000/svg" width="8.699ex" height="2.185ex" role="img" focusable="false" viewBox="0 -883.9 3845.1 965.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D438" d="M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z"></path></g><g data-mml-node="mo" transform="translate(1041.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(2097.6,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="msup" transform="translate(2975.6,0)"><g data-mml-node="mi"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mn" transform="translate(466,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g></g></svg></mjx-container><br>…..</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;测试&quot;&gt;&lt;a href=&quot;#测试&quot; class=&quot;headerlink&quot; title=&quot;测试&quot;&gt;&lt;/a&gt;测试&lt;/h1&gt;&lt;p&gt;终于搞好了555&lt;/p&gt;
&lt;p&gt;好开心&lt;br&gt;&lt;mjx-container class=&quot;MathJax&quot; jax=&quot;SVG&quot; displa</summary>
      
    
    
    
    
    <category term="测试" scheme="https://horacehht.github.io/tags/%E6%B5%8B%E8%AF%95/"/>
    
    <category term="试一下能不能多个标签" scheme="https://horacehht.github.io/tags/%E8%AF%95%E4%B8%80%E4%B8%8B%E8%83%BD%E4%B8%8D%E8%83%BD%E5%A4%9A%E4%B8%AA%E6%A0%87%E7%AD%BE/"/>
    
  </entry>
  
</feed>
